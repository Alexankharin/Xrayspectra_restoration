{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc07833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplott as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e9a4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ctr=0\\nAlldata=pd.DataFrame()\\nfor maxenergy in os.listdir('Allspecs/')[-6:]:\\n    path='Allspecs/'+maxenergy +'/'\\n    for filename in os.listdir(path):\\n        _,el1,size,el2=filename.split('_')\\n        el2=el2[:-4]\\n        size=float(size[:-2])\\n        name=str((el1,el2,size,maxenergy))\\n        singledata=pd.read_csv(path+ filename,sep=' ',names=['E',name])\\n        Alldata=pd.concat([Alldata,singledata[name]],axis=1)\\n        #Alldata[str((maxenergy,el1,el2,size))]=singledata['I']\\n        #ctr=ctr+1\\n    print (maxenergy)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ctr=0\n",
    "Alldata=pd.DataFrame()\n",
    "for maxenergy in os.listdir('Allspecs/')[-6:]:\n",
    "    path='Allspecs/'+maxenergy +'/'\n",
    "    for filename in os.listdir(path):\n",
    "        _,el1,size,el2=filename.split('_')\n",
    "        el2=el2[:-4]\n",
    "        size=float(size[:-2])\n",
    "        name=str((el1,el2,size,maxenergy))\n",
    "        singledata=pd.read_csv(path+ filename,sep=' ',names=['E',name])\n",
    "        Alldata=pd.concat([Alldata,singledata[name]],axis=1)\n",
    "        #Alldata[str((maxenergy,el1,el2,size))]=singledata['I']\n",
    "        #ctr=ctr+1\n",
    "    print (maxenergy)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aff5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5845/3221147074.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Alldata['E']=Alldata.index+1\n"
     ]
    }
   ],
   "source": [
    "Alldata=pd.read_pickle('allspecs.pkl')\n",
    "Alldata=Alldata[9:]\n",
    "Alldata=Alldata/Alldata.sum(0)\n",
    "Alldata['E']=Alldata.index+1\n",
    "Alldata=Alldata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200a982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/alex/anaconda3/envs/pytorch/lib/python3.10/site-packages (3.0.10)\r\n",
      "Requirement already satisfied: et-xmlfile in /home/alex/anaconda3/envs/pytorch/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b490e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monochromatic=pd.read_excel('Глубинные распределения.Вода.xlsx',header=1,skiprows=[0,1,1004,1005,1006],names=['N']+[str((a+10)) for a in range(241)])\n",
    "monochromaticnorm=monochromatic/monochromatic.sum(0)\n",
    "monochromaticnorm['N']=monochromatic['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d233ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions=(np.array(monochromaticnorm[monochromaticnorm.columns[1:]])@np.array(Alldata.fillna(0))[:,:-1]).T\n",
    "specs=np.array(Alldata[Alldata.columns[:-1]].fillna(0.0)).T\n",
    "basis=np.array(monochromaticnorm[monochromaticnorm.columns[1:]])\n",
    "basis=torch.tensor(basis).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b76b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dosedistr(torch.nn.Module):\n",
    "    def __init__(self, N_inputs=51561):\n",
    "        super().__init__()\n",
    "        self.specs=torch.nn.parameter.Parameter(data=torch.rand(241,N_inputs)/100, requires_grad=True)\n",
    "    def forward(self, basis):\n",
    "        outs=basis@self.specs\n",
    "        return outs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0481c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainstep(model,basis,target, optimizer,lossfn=torch.nn.MSELoss()):\n",
    "    optimizer.zero_grad()\n",
    "    out=model(basis)\n",
    "    l2_reg=0\n",
    "    #model.spectrum.weight.data[:,:,:]=model.spectrum.weight.data[:,:,:]/model.spectrum.weight.data[:,:,:].sum(1,keepdim=True)\n",
    "    #for param in model.parameters():\n",
    "    gradx=(model.specs[1:-1,:]-model.specs.roll(1,-2)[1:-1,:])*1\n",
    "    l2_smooth = gradx.square().mean()\n",
    "    loss=(lossfn(out, target)*10000+l2_smooth*1000)*target.shape[0]\n",
    "    #lossfn(out, target)*10000+l2_smooth\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    for p in model.parameters():\n",
    "        p.data.clamp_(0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4f6c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51561, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e3ad632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dosedistr()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda'\n",
    "dose=Dosedistr(51561).to(float).to(device)\n",
    "dose.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ccd730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(184661.6774, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>) tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "100 tensor(66015.7000, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>) tensor(0.0113, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "200 tensor(35056.9329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>) tensor(0.0187, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "300 tensor(22703.6686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>) tensor(0.0132, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "400 tensor(16132.8356, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>) tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "500 tensor(12140.7997, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "600 tensor(9519.4413, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "700 tensor(7694.2186, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "800 tensor(6370.5473, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "900 tensor(5385.2542, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0090, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1000 tensor(4631.3116, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0128, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1100 tensor(4041.5065, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0145, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1200 tensor(3565.2423, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0156, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1300 tensor(3175.0032, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0159, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1400 tensor(2855.9636, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0156, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1500 tensor(2587.8790, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0150, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1600 tensor(2364.2643, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0144, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1700 tensor(2173.8017, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0137, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1800 tensor(2011.6931, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0127, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "1900 tensor(1872.4281, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0118, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2000 tensor(1752.2192, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0107, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2100 tensor(1646.4043, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0098, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2200 tensor(1554.5331, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0090, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2300 tensor(1473.9342, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2400 tensor(1402.9875, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0077, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2500 tensor(1340.6228, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2600 tensor(1285.9628, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2700 tensor(1236.4058, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2800 tensor(1192.9986, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "2900 tensor(1155.8253, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3000 tensor(1122.3012, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0047, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3100 tensor(1093.2388, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0045, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3200 tensor(1067.7267, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3300 tensor(1044.8672, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3400 tensor(1025.6596, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3500 tensor(1007.7185, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3600 tensor(993.4988, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3700 tensor(980.9747, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3800 tensor(970.1970, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "3900 tensor(959.7587, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4000 tensor(952.5404, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0045, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4100 tensor(945.2153, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0045, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4200 tensor(939.6016, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4300 tensor(934.4564, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4400 tensor(931.4620, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0047, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4500 tensor(928.2832, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0047, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4600 tensor(926.0020, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4700 tensor(923.4766, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4800 tensor(921.4093, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "4900 tensor(920.5637, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 tensor(919.1078, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5100 tensor(917.4931, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5200 tensor(917.1337, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5300 tensor(916.3486, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5400 tensor(915.0353, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5500 tensor(914.6231, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5600 tensor(914.4611, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5700 tensor(913.8141, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5800 tensor(913.3627, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "5900 tensor(912.6705, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6000 tensor(912.2497, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6100 tensor(912.0439, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6200 tensor(912.0617, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6300 tensor(911.3511, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6400 tensor(911.8108, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6500 tensor(911.6238, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6600 tensor(911.4757, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6700 tensor(910.9081, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6800 tensor(911.8438, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "6900 tensor(911.3323, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7000 tensor(911.4042, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7100 tensor(911.1029, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7200 tensor(911.4592, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7300 tensor(911.0655, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7400 tensor(911.2134, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7500 tensor(910.6609, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7600 tensor(910.7989, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7700 tensor(910.7229, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7800 tensor(910.2125, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "7900 tensor(910.3198, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8000 tensor(910.2239, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8100 tensor(909.3383, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8200 tensor(909.7081, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8300 tensor(909.6363, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8400 tensor(910.1742, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8500 tensor(909.7642, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8600 tensor(909.7187, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8700 tensor(909.8540, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8800 tensor(909.8487, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "8900 tensor(910.1024, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9000 tensor(909.6547, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9100 tensor(910.1715, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9200 tensor(910.1532, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9300 tensor(909.9617, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9400 tensor(909.8112, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9500 tensor(909.9434, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9600 tensor(909.6682, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9700 tensor(909.8627, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9800 tensor(909.5209, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "9900 tensor(909.7386, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 tensor(910.2181, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10100 tensor(910.0240, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10200 tensor(909.9668, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10300 tensor(910.2538, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10400 tensor(910.2357, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10500 tensor(910.1382, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10600 tensor(910.4149, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10700 tensor(910.8006, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10800 tensor(910.5379, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "10900 tensor(910.4896, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11000 tensor(910.6125, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11100 tensor(910.7656, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11200 tensor(910.1902, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11300 tensor(910.2239, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11400 tensor(910.3205, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11500 tensor(909.9610, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11600 tensor(910.5460, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11700 tensor(910.4349, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11800 tensor(910.3165, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "11900 tensor(910.1518, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12000 tensor(910.6766, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12100 tensor(910.2077, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12200 tensor(910.4503, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12300 tensor(910.2493, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12400 tensor(910.2971, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12500 tensor(910.2050, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12600 tensor(910.2770, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12700 tensor(909.9731, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12800 tensor(910.3028, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "12900 tensor(910.3982, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13000 tensor(910.5595, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13100 tensor(910.2708, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13200 tensor(910.4066, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13300 tensor(910.5731, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13400 tensor(910.3521, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13500 tensor(910.6806, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13600 tensor(910.5559, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13700 tensor(910.6543, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13800 tensor(910.6540, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "13900 tensor(910.6430, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14000 tensor(910.5028, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14100 tensor(910.1060, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14200 tensor(910.4656, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14300 tensor(910.6571, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14400 tensor(910.2013, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14500 tensor(909.9964, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14600 tensor(910.8014, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14700 tensor(910.1291, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14800 tensor(910.8436, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "14900 tensor(910.4571, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 tensor(911.1174, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "15100 tensor(910.9512, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>) tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     lossesADAM\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m----> 8\u001b[0m loss\u001b[38;5;241m=\u001b[39mtrainstep(dose, basis\u001b[38;5;241m.\u001b[39mto(device),\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistributions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m,optimizerADAM,lossfn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mL1Loss())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i,loss,dose\u001b[38;5;241m.\u001b[39mspecs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossesADAM=[]\n",
    "optimizerADAM=torch.optim.Adam(dose.parameters(), lr=0.0001)\n",
    "for i in range(30900):\n",
    "    #print(i)\n",
    "    if i%100==51:\n",
    "        continue\n",
    "        lossesADAM.append(loss.detach().cpu().numpy())\n",
    "    loss=trainstep(dose, basis.to(device),torch.tensor(distributions).to(device),optimizerADAM,lossfn=torch.nn.L1Loss())\n",
    "    if i%100==0:\n",
    "        print(i,loss,dose.specs[0][0])\n",
    "    if i<-2000 and i%200==1:\n",
    "        dose.specs.data=dose.specs.data+torch.rand(dose.specs.data.shape).to(device)*0.01\n",
    "outs[number]=dose.specs.data.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595a73e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90aea164d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM=30000\n",
    "plt.plot(dose.specs[:,NUM].cpu().detach())\n",
    "plt.plot(specs[NUM,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea698993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('roughrestoredspecs2.npy',dose.specs.data.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1034e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "specsrestored=np.load('roughrestoredspecs2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0061d1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ag', 'Cu', 'Mo', 'Pd', 'Rh', 'W'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([col.split(',')[1][2:-1] for col in Alldata.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a53bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElementClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=torch.nn.Conv1d(1,32,3,padding=1)\n",
    "        self.bn1=torch.nn.BatchNorm1d(32)\n",
    "        self.conv2=torch.nn.Conv1d(32,1,3,padding=1)\n",
    "        self.bn2=torch.nn.BatchNorm1d(1)\n",
    "        self.classifier=torch.nn.Linear(1000,7)\n",
    "        self.linear=torch.nn.Linear(1000,1000)\n",
    "        self.activation=torch.nn.functional.elu\n",
    "    def forward(self,x):\n",
    "        b,c,l=x.shape\n",
    "        y=self.bn1(self.activation(self.conv1(x)))\n",
    "        y=self.bn2(self.activation(self.conv2(y)))\n",
    "        y=self.activation(self.linear(y.reshape(b,-1)))\n",
    "        y=self.classifier(y)\n",
    "        return y.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c12dc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainstepClass(model,inps,targets, optimizer,lossfn=torch.nn.CrossEntropyLoss()):\n",
    "    optimizer.zero_grad()\n",
    "    out=model(inps)\n",
    "    loss=lossfn(out, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    onehot=torch.nn.functional.one_hot(out.argmax(-1),num_classes=7)\n",
    "    #print(onehot.shape, targets.shape)\n",
    "    #print((out).mean(0),targets.mean(0))\n",
    "    acc=(onehot*targets).sum(0).sum(0)/targets.shape[0]\n",
    "    #mean=one\n",
    "    return loss,acc#,mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53ba3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=torch.load('classifier.pt').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "691ac5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(classifier,'classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de595d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3603, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 0 24\n",
      "val_acc 0.81396484 0\n",
      "tensor(1.3265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 1 24\n",
      "val_acc 0.8144531 1\n",
      "tensor(1.3319, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 2 24\n",
      "val_acc 0.8129883 2\n",
      "tensor(1.3376, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 3 24\n",
      "val_acc 0.8144531 3\n",
      "tensor(1.3669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 4 24\n",
      "val_acc 0.8144531 4\n",
      "tensor(1.3549, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 5 24\n",
      "val_acc 0.81347656 5\n",
      "tensor(1.3546, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 6 24\n",
      "val_acc 0.81689453 6\n",
      "tensor(1.3303, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 7 24\n",
      "val_acc 0.8071289 7\n",
      "tensor(1.3545, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 8 24\n",
      "val_acc 0.8149414 8\n",
      "tensor(1.3586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 9 24\n",
      "val_acc 0.81640625 9\n",
      "tensor(1.3681, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7977839335180056 10 24\n",
      "val_acc 0.8173828 10\n",
      "tensor(1.3539, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 11 24\n",
      "val_acc 0.8173828 11\n",
      "tensor(1.3181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.850415512465374 12 24\n",
      "val_acc 0.8178711 12\n",
      "tensor(1.3262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 13 24\n",
      "val_acc 0.8178711 13\n",
      "tensor(1.3631, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 14 24\n",
      "val_acc 0.8120117 14\n",
      "tensor(1.3324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 15 24\n",
      "val_acc 0.81884766 15\n",
      "tensor(1.3404, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 16 24\n",
      "val_acc 0.8178711 16\n",
      "tensor(1.3557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 17 24\n",
      "val_acc 0.81591797 17\n",
      "tensor(1.3686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 18 24\n",
      "val_acc 0.81640625 18\n",
      "tensor(1.3616, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 19 24\n",
      "val_acc 0.8120117 19\n",
      "tensor(1.3279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 20 24\n",
      "val_acc 0.81884766 20\n",
      "tensor(1.4051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7562326869806094 21 24\n",
      "val_acc 0.81884766 21\n",
      "tensor(1.3587, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 22 24\n",
      "val_acc 0.81884766 22\n",
      "tensor(1.3114, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.853185595567867 23 24\n",
      "val_acc 0.8178711 23\n",
      "tensor(1.3473, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 24 24\n",
      "val_acc 0.8120117 24\n",
      "tensor(1.2914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8753462603878116 25 24\n",
      "val_acc 0.81884766 25\n",
      "tensor(1.3343, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 26 24\n",
      "val_acc 0.81933594 26\n",
      "tensor(1.3349, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 27 24\n",
      "val_acc 0.81933594 27\n",
      "tensor(1.3142, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.853185595567867 28 24\n",
      "val_acc 0.81884766 28\n",
      "tensor(1.3235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 29 24\n",
      "val_acc 0.81884766 29\n",
      "tensor(1.3471, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 30 24\n",
      "val_acc 0.81884766 30\n",
      "tensor(1.2997, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 31 24\n",
      "val_acc 0.81884766 31\n",
      "tensor(1.3316, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 32 24\n",
      "val_acc 0.81884766 32\n",
      "tensor(1.3271, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 33 24\n",
      "val_acc 0.81884766 33\n",
      "tensor(1.3169, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 34 24\n",
      "val_acc 0.81884766 34\n",
      "tensor(1.2888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8753462603878116 35 24\n",
      "val_acc 0.81884766 35\n",
      "tensor(1.3885, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7700831024930748 36 24\n",
      "val_acc 0.81884766 36\n",
      "tensor(1.3849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.775623268698061 37 24\n",
      "val_acc 0.81884766 37\n",
      "tensor(1.3572, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 38 24\n",
      "val_acc 0.8183594 38\n",
      "tensor(1.3151, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.850415512465374 39 24\n",
      "val_acc 0.8144531 39\n",
      "tensor(1.3584, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 40 24\n",
      "val_acc 0.81884766 40\n",
      "tensor(1.3425, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 41 24\n",
      "val_acc 0.81884766 41\n",
      "tensor(1.3252, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 42 24\n",
      "val_acc 0.81884766 42\n",
      "tensor(1.3329, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 43 24\n",
      "val_acc 0.81933594 43\n",
      "tensor(1.3610, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 44 24\n",
      "val_acc 0.81933594 44\n",
      "tensor(1.3586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 45 24\n",
      "val_acc 0.81933594 45\n",
      "tensor(1.3386, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 46 24\n",
      "val_acc 0.8198242 46\n",
      "tensor(1.3543, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 47 24\n",
      "val_acc 0.81933594 47\n",
      "tensor(1.3445, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 48 24\n",
      "val_acc 0.8198242 48\n",
      "tensor(1.3419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 49 24\n",
      "val_acc 0.81933594 49\n",
      "tensor(1.3436, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 50 24\n",
      "val_acc 0.8198242 50\n",
      "tensor(1.3170, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 51 24\n",
      "val_acc 0.81933594 51\n",
      "tensor(1.3827, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.775623268698061 52 24\n",
      "val_acc 0.81933594 52\n",
      "tensor(1.3680, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7922437673130194 53 24\n",
      "val_acc 0.8198242 53\n",
      "tensor(1.3305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 54 24\n",
      "val_acc 0.81933594 54\n",
      "tensor(1.3687, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7922437673130194 55 24\n",
      "val_acc 0.81933594 55\n",
      "tensor(1.3468, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 56 24\n",
      "val_acc 0.8198242 56\n",
      "tensor(1.3481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 57 24\n",
      "val_acc 0.81933594 57\n",
      "tensor(1.3595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 58 24\n",
      "val_acc 0.81933594 58\n",
      "tensor(1.3224, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 59 24\n",
      "val_acc 0.81933594 59\n",
      "tensor(1.3246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 60 24\n",
      "val_acc 0.8198242 60\n",
      "tensor(1.3514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 61 24\n",
      "val_acc 0.8198242 61\n",
      "tensor(1.3278, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 62 24\n",
      "val_acc 0.81884766 62\n",
      "tensor(1.3196, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 63 24\n",
      "val_acc 0.81933594 63\n",
      "tensor(1.3253, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 64 24\n",
      "val_acc 0.81933594 64\n",
      "tensor(1.3417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 65 24\n",
      "val_acc 0.8154297 65\n",
      "tensor(1.3463, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 66 24\n",
      "val_acc 0.8120117 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3175, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 67 24\n",
      "val_acc 0.81347656 67\n",
      "tensor(1.3436, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 68 24\n",
      "val_acc 0.81933594 68\n",
      "tensor(1.3664, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7922437673130194 69 24\n",
      "val_acc 0.81884766 69\n",
      "tensor(1.3538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 70 24\n",
      "val_acc 0.81933594 70\n",
      "tensor(1.3677, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7922437673130194 71 24\n",
      "val_acc 0.8198242 71\n",
      "tensor(1.3512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 72 24\n",
      "val_acc 0.8198242 72\n",
      "tensor(1.3668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 73 24\n",
      "val_acc 0.81933594 73\n",
      "tensor(1.3421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 74 24\n",
      "val_acc 0.81933594 74\n",
      "tensor(1.3275, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 75 24\n",
      "val_acc 0.8198242 75\n",
      "tensor(1.3790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.778393351800554 76 24\n",
      "val_acc 0.8198242 76\n",
      "tensor(1.3240, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 77 24\n",
      "val_acc 0.81884766 77\n",
      "tensor(1.3368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 78 24\n",
      "val_acc 0.81933594 78\n",
      "tensor(1.3056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8587257617728532 79 24\n",
      "val_acc 0.8198242 79\n",
      "tensor(1.3347, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 80 24\n",
      "val_acc 0.8198242 80\n",
      "tensor(1.3270, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 81 24\n",
      "val_acc 0.8198242 81\n",
      "tensor(1.3413, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 82 24\n",
      "val_acc 0.8198242 82\n",
      "tensor(1.3002, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 83 24\n",
      "val_acc 0.8183594 83\n",
      "tensor(1.3577, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 84 24\n",
      "val_acc 0.81103516 84\n",
      "tensor(1.3743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7839335180055401 85 24\n",
      "val_acc 0.8183594 85\n",
      "tensor(1.3576, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 86 24\n",
      "val_acc 0.79248047 86\n",
      "tensor(1.6473, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.5124653739612188 87 24\n",
      "val_acc 0.55810547 87\n",
      "tensor(1.4166, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7506925207756233 88 24\n",
      "val_acc 0.6972656 88\n",
      "tensor(1.4062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7645429362880887 89 24\n",
      "val_acc 0.76171875 89\n",
      "tensor(1.3527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 90 24\n",
      "val_acc 0.73828125 90\n",
      "tensor(1.3568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 91 24\n",
      "val_acc 0.81591797 91\n",
      "tensor(1.3635, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 92 24\n",
      "val_acc 0.8198242 92\n",
      "tensor(1.3341, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 93 24\n",
      "val_acc 0.8198242 93\n",
      "tensor(1.3415, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 94 24\n",
      "val_acc 0.8198242 94\n",
      "tensor(1.3215, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 95 24\n",
      "val_acc 0.8198242 95\n",
      "tensor(1.3297, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 96 24\n",
      "val_acc 0.8198242 96\n",
      "tensor(1.3380, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 97 24\n",
      "val_acc 0.81933594 97\n",
      "tensor(1.3307, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 98 24\n",
      "val_acc 0.8198242 98\n",
      "tensor(1.3632, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 99 24\n",
      "val_acc 0.8198242 99\n",
      "tensor(1.3520, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 100 24\n",
      "val_acc 0.8198242 100\n",
      "tensor(1.3420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 101 24\n",
      "val_acc 0.8198242 101\n",
      "tensor(1.3595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 102 24\n",
      "val_acc 0.8198242 102\n",
      "tensor(1.3304, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 103 24\n",
      "val_acc 0.8198242 103\n",
      "tensor(1.3438, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 104 24\n",
      "val_acc 0.8198242 104\n",
      "tensor(1.3225, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 105 24\n",
      "val_acc 0.8198242 105\n",
      "tensor(1.3218, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 106 24\n",
      "val_acc 0.8198242 106\n",
      "tensor(1.3797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.778393351800554 107 24\n",
      "val_acc 0.8198242 107\n",
      "tensor(1.3481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 108 24\n",
      "val_acc 0.8198242 108\n",
      "tensor(1.3486, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 109 24\n",
      "val_acc 0.8198242 109\n",
      "tensor(1.3136, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 110 24\n",
      "val_acc 0.8198242 110\n",
      "tensor(1.3412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 111 24\n",
      "val_acc 0.8198242 111\n",
      "tensor(1.3228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 112 24\n",
      "val_acc 0.8198242 112\n",
      "tensor(1.3175, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 113 24\n",
      "val_acc 0.8198242 113\n",
      "tensor(1.3383, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 114 24\n",
      "val_acc 0.8198242 114\n",
      "tensor(1.3443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 115 24\n",
      "val_acc 0.81933594 115\n",
      "tensor(1.3296, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 116 24\n",
      "val_acc 0.8203125 116\n",
      "tensor(1.3586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 117 24\n",
      "val_acc 0.8198242 117\n",
      "tensor(1.3479, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 118 24\n",
      "val_acc 0.8203125 118\n",
      "tensor(1.3570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 119 24\n",
      "val_acc 0.8203125 119\n",
      "tensor(1.3479, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 120 24\n",
      "val_acc 0.8203125 120\n",
      "tensor(1.3351, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 121 24\n",
      "val_acc 0.8198242 121\n",
      "tensor(1.3382, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 122 24\n",
      "val_acc 0.8198242 122\n",
      "tensor(1.3368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 123 24\n",
      "val_acc 0.8198242 123\n",
      "tensor(1.4022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7562326869806094 124 24\n",
      "val_acc 0.8198242 124\n",
      "tensor(1.3568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 125 24\n",
      "val_acc 0.8203125 125\n",
      "tensor(1.2975, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 126 24\n",
      "val_acc 0.8203125 126\n",
      "tensor(1.3597, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 127 24\n",
      "val_acc 0.8198242 127\n",
      "tensor(1.3182, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 128 24\n",
      "val_acc 0.8198242 128\n",
      "tensor(1.3178, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 129 24\n",
      "val_acc 0.8198242 129\n",
      "tensor(1.3335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 130 24\n",
      "val_acc 0.8198242 130\n",
      "tensor(1.3481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 131 24\n",
      "val_acc 0.8198242 131\n",
      "tensor(1.3140, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 132 24\n",
      "val_acc 0.8203125 132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 133 24\n",
      "val_acc 0.8203125 133\n",
      "tensor(1.3421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 134 24\n",
      "val_acc 0.8203125 134\n",
      "tensor(1.3339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 135 24\n",
      "val_acc 0.8203125 135\n",
      "tensor(1.3265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 136 24\n",
      "val_acc 0.8198242 136\n",
      "tensor(1.3305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 137 24\n",
      "val_acc 0.8203125 137\n",
      "tensor(1.3246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 138 24\n",
      "val_acc 0.8203125 138\n",
      "tensor(1.3329, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 139 24\n",
      "val_acc 0.8203125 139\n",
      "tensor(1.3641, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 140 24\n",
      "val_acc 0.8203125 140\n",
      "tensor(1.3365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 141 24\n",
      "val_acc 0.8203125 141\n",
      "tensor(1.3200, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 142 24\n",
      "val_acc 0.8208008 142\n",
      "tensor(1.3062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8559556786703602 143 24\n",
      "val_acc 0.8203125 143\n",
      "tensor(1.3640, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 144 24\n",
      "val_acc 0.8198242 144\n",
      "tensor(1.3501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 145 24\n",
      "val_acc 0.8203125 145\n",
      "tensor(1.3130, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 146 24\n",
      "val_acc 0.8203125 146\n",
      "tensor(1.3137, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 147 24\n",
      "val_acc 0.8203125 147\n",
      "tensor(1.3440, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 148 24\n",
      "val_acc 0.8203125 148\n",
      "tensor(1.3388, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 149 24\n",
      "val_acc 0.8203125 149\n",
      "tensor(1.3190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 150 24\n",
      "val_acc 0.8203125 150\n",
      "tensor(1.3248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 151 24\n",
      "val_acc 0.8198242 151\n",
      "tensor(1.3508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 152 24\n",
      "val_acc 0.8208008 152\n",
      "tensor(1.3480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 153 24\n",
      "val_acc 0.8203125 153\n",
      "tensor(1.2978, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 154 24\n",
      "val_acc 0.8203125 154\n",
      "tensor(1.3188, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 155 24\n",
      "val_acc 0.8208008 155\n",
      "tensor(1.3668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7922437673130194 156 24\n",
      "val_acc 0.8208008 156\n",
      "tensor(1.3957, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7700831024930748 157 24\n",
      "val_acc 0.76660156 157\n",
      "tensor(1.3152, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.853185595567867 158 24\n",
      "val_acc 0.81933594 158\n",
      "tensor(1.3390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 159 24\n",
      "val_acc 0.8198242 159\n",
      "tensor(1.3396, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 160 24\n",
      "val_acc 0.8203125 160\n",
      "tensor(1.3580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 161 24\n",
      "val_acc 0.8198242 161\n",
      "tensor(1.3341, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 162 24\n",
      "val_acc 0.8203125 162\n",
      "tensor(1.3414, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 163 24\n",
      "val_acc 0.8203125 163\n",
      "tensor(1.3447, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 164 24\n",
      "val_acc 0.8203125 164\n",
      "tensor(1.3157, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 165 24\n",
      "val_acc 0.8203125 165\n",
      "tensor(1.3263, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 166 24\n",
      "val_acc 0.8203125 166\n",
      "tensor(1.3510, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 167 24\n",
      "val_acc 0.8203125 167\n",
      "tensor(1.3586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 168 24\n",
      "val_acc 0.82128906 168\n",
      "tensor(1.3454, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 169 24\n",
      "val_acc 0.8208008 169\n",
      "tensor(1.3417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 170 24\n",
      "val_acc 0.8203125 170\n",
      "tensor(1.3691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7894736842105263 171 24\n",
      "val_acc 0.8203125 171\n",
      "tensor(1.3079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.853185595567867 172 24\n",
      "val_acc 0.8203125 172\n",
      "tensor(1.3156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 173 24\n",
      "val_acc 0.8203125 173\n",
      "tensor(1.3053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8559556786703602 174 24\n",
      "val_acc 0.8203125 174\n",
      "tensor(1.3696, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7894736842105263 175 24\n",
      "val_acc 0.8208008 175\n",
      "tensor(1.3135, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 176 24\n",
      "val_acc 0.8203125 176\n",
      "tensor(1.3243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 177 24\n",
      "val_acc 0.8208008 177\n",
      "tensor(1.3122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 178 24\n",
      "val_acc 0.8208008 178\n",
      "tensor(1.3502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 179 24\n",
      "val_acc 0.8203125 179\n",
      "tensor(1.3159, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 180 24\n",
      "val_acc 0.82177734 180\n",
      "tensor(1.3356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 181 24\n",
      "val_acc 0.82177734 181\n",
      "tensor(1.3341, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 182 24\n",
      "val_acc 0.8208008 182\n",
      "tensor(1.3321, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 183 24\n",
      "val_acc 0.8203125 183\n",
      "tensor(1.3509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 184 24\n",
      "val_acc 0.8208008 184\n",
      "tensor(1.3042, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8587257617728532 185 24\n",
      "val_acc 0.8203125 185\n",
      "tensor(1.3158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 186 24\n",
      "val_acc 0.82128906 186\n",
      "tensor(1.3248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 187 24\n",
      "val_acc 0.8203125 187\n",
      "tensor(1.3293, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 188 24\n",
      "val_acc 0.8203125 188\n",
      "tensor(1.3554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 189 24\n",
      "val_acc 0.8203125 189\n",
      "tensor(1.3274, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 190 24\n",
      "val_acc 0.8203125 190\n",
      "tensor(1.3119, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 191 24\n",
      "val_acc 0.8208008 191\n",
      "tensor(1.3485, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 192 24\n",
      "val_acc 0.82177734 192\n",
      "tensor(1.3315, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 193 24\n",
      "val_acc 0.8208008 193\n",
      "tensor(1.3688, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7894736842105263 194 24\n",
      "val_acc 0.8208008 194\n",
      "tensor(1.3229, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 195 24\n",
      "val_acc 0.8203125 195\n",
      "tensor(1.3577, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 196 24\n",
      "val_acc 0.8208008 196\n",
      "tensor(1.3249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 197 24\n",
      "val_acc 0.8208008 197\n",
      "tensor(1.3227, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 198 24\n",
      "val_acc 0.8208008 198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3325, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 199 24\n",
      "val_acc 0.82177734 199\n",
      "tensor(1.3130, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 200 24\n",
      "val_acc 0.8208008 200\n",
      "tensor(1.2966, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 201 24\n",
      "val_acc 0.82177734 201\n",
      "tensor(1.3336, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 202 24\n",
      "val_acc 0.8208008 202\n",
      "tensor(1.3184, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 203 24\n",
      "val_acc 0.8203125 203\n",
      "tensor(1.3189, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 204 24\n",
      "val_acc 0.82177734 204\n",
      "tensor(1.3259, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 205 24\n",
      "val_acc 0.82177734 205\n",
      "tensor(1.3378, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 206 24\n",
      "val_acc 0.82128906 206\n",
      "tensor(1.3475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 207 24\n",
      "val_acc 0.8222656 207\n",
      "tensor(1.3397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 208 24\n",
      "val_acc 0.8222656 208\n",
      "tensor(1.3445, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 209 24\n",
      "val_acc 0.8198242 209\n",
      "tensor(1.3435, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.817174515235457 210 24\n",
      "val_acc 0.82177734 210\n",
      "tensor(1.3405, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 211 24\n",
      "val_acc 0.82128906 211\n",
      "tensor(1.3385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 212 24\n",
      "val_acc 0.82128906 212\n",
      "tensor(1.3209, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 213 24\n",
      "val_acc 0.82128906 213\n",
      "tensor(1.3666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7894736842105263 214 24\n",
      "val_acc 0.8222656 214\n",
      "tensor(1.3495, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 215 24\n",
      "val_acc 0.82177734 215\n",
      "tensor(1.3587, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 216 24\n",
      "val_acc 0.82128906 216\n",
      "tensor(1.3235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 217 24\n",
      "val_acc 0.8222656 217\n",
      "tensor(1.3484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8116343490304709 218 24\n",
      "val_acc 0.82128906 218\n",
      "tensor(1.3275, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 219 24\n",
      "val_acc 0.82128906 219\n",
      "tensor(1.3571, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8033240997229917 220 24\n",
      "val_acc 0.8222656 220\n",
      "tensor(1.3653, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 221 24\n",
      "val_acc 0.8095703 221\n",
      "tensor(1.3238, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 222 24\n",
      "val_acc 0.8222656 222\n",
      "tensor(1.3738, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7867036011080333 223 24\n",
      "val_acc 0.8076172 223\n",
      "tensor(1.3184, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 224 24\n",
      "val_acc 0.81347656 224\n",
      "tensor(1.3632, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 225 24\n",
      "val_acc 0.81640625 225\n",
      "tensor(1.3086, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.853185595567867 226 24\n",
      "val_acc 0.8071289 226\n",
      "tensor(1.3663, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7922437673130194 227 24\n",
      "val_acc 0.8105469 227\n",
      "tensor(1.3415, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 228 24\n",
      "val_acc 0.80859375 228\n",
      "tensor(1.3393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 229 24\n",
      "val_acc 0.81103516 229\n",
      "tensor(1.3701, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7894736842105263 230 24\n",
      "val_acc 0.8183594 230\n",
      "tensor(1.4220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7368421052631579 231 24\n",
      "val_acc 0.79785156 231\n",
      "tensor(1.4780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.6925207756232687 232 24\n",
      "val_acc 0.7182617 232\n",
      "tensor(1.4148, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7451523545706371 233 24\n",
      "val_acc 0.7314453 233\n",
      "tensor(1.4501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7146814404432132 234 24\n",
      "val_acc 0.7138672 234\n",
      "tensor(1.4050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7562326869806094 235 24\n",
      "val_acc 0.7397461 235\n",
      "tensor(1.3332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8337950138504155 236 24\n",
      "val_acc 0.76904297 236\n",
      "tensor(1.3768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7839335180055401 237 24\n",
      "val_acc 0.8149414 237\n",
      "tensor(1.2982, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 238 24\n",
      "val_acc 0.8222656 238\n",
      "tensor(1.3335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 239 24\n",
      "val_acc 0.82177734 239\n",
      "tensor(1.3368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 240 24\n",
      "val_acc 0.8222656 240\n",
      "tensor(1.3173, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 241 24\n",
      "val_acc 0.8222656 241\n",
      "tensor(1.3497, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8088642659279779 242 24\n",
      "val_acc 0.8222656 242\n",
      "tensor(1.3533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8060941828254847 243 24\n",
      "val_acc 0.8227539 243\n",
      "tensor(1.3004, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8614958448753463 244 24\n",
      "val_acc 0.8232422 244\n",
      "tensor(1.3147, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8476454293628809 245 24\n",
      "val_acc 0.82373047 245\n",
      "tensor(1.3639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7950138504155124 246 24\n",
      "val_acc 0.8222656 246\n",
      "tensor(1.3173, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 247 24\n",
      "val_acc 0.8232422 247\n",
      "tensor(1.3231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 248 24\n",
      "val_acc 0.82373047 248\n",
      "tensor(1.3317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 249 24\n",
      "val_acc 0.8232422 249\n",
      "tensor(1.3395, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 250 24\n",
      "val_acc 0.82373047 250\n",
      "tensor(1.3368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8227146814404432 251 24\n",
      "val_acc 0.8232422 251\n",
      "tensor(1.3189, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 252 24\n",
      "val_acc 0.82421875 252\n",
      "tensor(1.3342, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 253 24\n",
      "val_acc 0.8222656 253\n",
      "tensor(1.3056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8559556786703602 254 24\n",
      "val_acc 0.8222656 254\n",
      "tensor(1.3317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 255 24\n",
      "val_acc 0.8232422 255\n",
      "tensor(1.3570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 256 24\n",
      "val_acc 0.8232422 256\n",
      "tensor(1.3247, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 257 24\n",
      "val_acc 0.8251953 257\n",
      "tensor(1.3593, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8005540166204986 258 24\n",
      "val_acc 0.82666016 258\n",
      "tensor(1.3368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 259 24\n",
      "val_acc 0.82421875 259\n",
      "tensor(1.3298, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 260 24\n",
      "val_acc 0.82666016 260\n",
      "tensor(1.3294, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8310249307479224 261 24\n",
      "val_acc 0.83154297 261\n",
      "tensor(1.3396, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 262 24\n",
      "val_acc 0.8300781 262\n",
      "tensor(1.3356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8254847645429363 263 24\n",
      "val_acc 0.83154297 263\n",
      "tensor(1.3023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8587257617728532 264 24\n",
      "val_acc 0.8330078 264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3106, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.850415512465374 265 24\n",
      "val_acc 0.8330078 265\n",
      "tensor(1.3458, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 266 24\n",
      "val_acc 0.83154297 266\n",
      "tensor(1.3161, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 267 24\n",
      "val_acc 0.83203125 267\n",
      "tensor(1.3181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8421052631578947 268 24\n",
      "val_acc 0.8330078 268\n",
      "tensor(1.3250, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 269 24\n",
      "val_acc 0.83251953 269\n",
      "tensor(1.3375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8199445983379502 270 24\n",
      "val_acc 0.8339844 270\n",
      "tensor(1.3467, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.814404432132964 271 24\n",
      "val_acc 0.8334961 271\n",
      "tensor(1.3154, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 272 24\n",
      "val_acc 0.83447266 272\n",
      "tensor(1.3319, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8282548476454293 273 24\n",
      "val_acc 0.83447266 273\n",
      "tensor(1.3047, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8559556786703602 274 24\n",
      "val_acc 0.83496094 274\n",
      "tensor(1.3140, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 275 24\n",
      "val_acc 0.83496094 275\n",
      "tensor(1.3740, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7839335180055401 276 24\n",
      "val_acc 0.8354492 276\n",
      "tensor(1.3203, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8393351800554016 277 24\n",
      "val_acc 0.8442383 277\n",
      "tensor(1.3183, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 278 24\n",
      "val_acc 0.86816406 278\n",
      "tensor(1.2734, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8919667590027701 279 24\n",
      "val_acc 0.8911133 279\n",
      "tensor(1.2648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9002770083102493 280 24\n",
      "val_acc 0.8911133 280\n",
      "tensor(1.2728, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.889196675900277 281 24\n",
      "val_acc 0.89160156 281\n",
      "tensor(1.2615, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9058171745152355 282 24\n",
      "val_acc 0.8911133 282\n",
      "tensor(1.2717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8919667590027701 283 24\n",
      "val_acc 0.8935547 283\n",
      "tensor(1.2562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9085872576177285 284 24\n",
      "val_acc 0.8930664 284\n",
      "tensor(1.2745, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8864265927977839 285 24\n",
      "val_acc 0.890625 285\n",
      "tensor(1.2992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 286 24\n",
      "val_acc 0.8925781 286\n",
      "tensor(1.2550, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9113573407202216 287 24\n",
      "val_acc 0.89404297 287\n",
      "tensor(1.2711, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8947368421052632 288 24\n",
      "val_acc 0.8911133 288\n",
      "tensor(1.2692, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8975069252077562 289 24\n",
      "val_acc 0.8911133 289\n",
      "tensor(1.2811, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8808864265927978 290 24\n",
      "val_acc 0.88916016 290\n",
      "tensor(1.2365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 291 24\n",
      "val_acc 0.89453125 291\n",
      "tensor(1.2556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9085872576177285 292 24\n",
      "val_acc 0.89404297 292\n",
      "tensor(1.2453, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 293 24\n",
      "val_acc 0.8881836 293\n",
      "tensor(1.2770, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.889196675900277 294 24\n",
      "val_acc 0.8911133 294\n",
      "tensor(1.2514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9141274238227147 295 24\n",
      "val_acc 0.8955078 295\n",
      "tensor(1.2383, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 296 24\n",
      "val_acc 0.8979492 296\n",
      "tensor(1.2618, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9030470914127424 297 24\n",
      "val_acc 0.89453125 297\n",
      "tensor(1.2483, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 298 24\n",
      "val_acc 0.8964844 298\n",
      "tensor(1.2548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9113573407202216 299 24\n",
      "val_acc 0.89501953 299\n",
      "tensor(1.2602, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9058171745152355 300 24\n",
      "val_acc 0.8984375 300\n",
      "tensor(1.2527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9141274238227147 301 24\n",
      "val_acc 0.8959961 301\n",
      "tensor(1.2677, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8975069252077562 302 24\n",
      "val_acc 0.8959961 302\n",
      "tensor(1.2509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9141274238227147 303 24\n",
      "val_acc 0.8964844 303\n",
      "tensor(1.2451, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 304 24\n",
      "val_acc 0.89746094 304\n",
      "tensor(1.2912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8725761772853186 305 24\n",
      "val_acc 0.8989258 305\n",
      "tensor(1.2573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9085872576177285 306 24\n",
      "val_acc 0.89501953 306\n",
      "tensor(1.2977, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8670360110803325 307 24\n",
      "val_acc 0.8964844 307\n",
      "tensor(1.2605, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9030470914127424 308 24\n",
      "val_acc 0.8989258 308\n",
      "tensor(1.2628, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9030470914127424 309 24\n",
      "val_acc 0.89746094 309\n",
      "tensor(1.2737, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.889196675900277 310 24\n",
      "val_acc 0.89697266 310\n",
      "tensor(1.2669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9002770083102493 311 24\n",
      "val_acc 0.8979492 311\n",
      "tensor(1.2666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9002770083102493 312 24\n",
      "val_acc 0.89990234 312\n",
      "tensor(1.2539, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9113573407202216 313 24\n",
      "val_acc 0.9003906 313\n",
      "tensor(1.2621, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9058171745152355 314 24\n",
      "val_acc 0.90185547 314\n",
      "tensor(1.2658, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9002770083102493 315 24\n",
      "val_acc 0.9013672 315\n",
      "tensor(1.2861, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8808864265927978 316 24\n",
      "val_acc 0.9033203 316\n",
      "tensor(1.2490, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9168975069252078 317 24\n",
      "val_acc 0.89941406 317\n",
      "tensor(1.2681, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8975069252077562 318 24\n",
      "val_acc 0.90283203 318\n",
      "tensor(1.2492, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9141274238227147 319 24\n",
      "val_acc 0.9038086 319\n",
      "tensor(1.2421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.925207756232687 320 24\n",
      "val_acc 0.9013672 320\n",
      "tensor(1.2480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 321 24\n",
      "val_acc 0.90283203 321\n",
      "tensor(1.2520, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 322 24\n",
      "val_acc 0.90527344 322\n",
      "tensor(1.2449, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 323 24\n",
      "val_acc 0.90625 323\n",
      "tensor(1.2433, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 324 24\n",
      "val_acc 0.90234375 324\n",
      "tensor(1.2760, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8919667590027701 325 24\n",
      "val_acc 0.9033203 325\n",
      "tensor(1.2989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8670360110803325 326 24\n",
      "val_acc 0.875 326\n",
      "tensor(1.2462, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 327 24\n",
      "val_acc 0.90966797 327\n",
      "tensor(1.2586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9141274238227147 328 24\n",
      "val_acc 0.9082031 328\n",
      "tensor(1.2626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9168975069252078 329 24\n",
      "val_acc 0.91748047 329\n",
      "tensor(1.2228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 330 24\n",
      "val_acc 0.91503906 330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2274, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 331 24\n",
      "val_acc 0.9140625 331\n",
      "tensor(1.2387, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 332 24\n",
      "val_acc 0.9160156 332\n",
      "tensor(1.2564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9168975069252078 333 24\n",
      "val_acc 0.9067383 333\n",
      "tensor(1.2392, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 334 24\n",
      "val_acc 0.9165039 334\n",
      "tensor(1.2335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 335 24\n",
      "val_acc 0.9189453 335\n",
      "tensor(1.2589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9168975069252078 336 24\n",
      "val_acc 0.91308594 336\n",
      "tensor(1.2251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 337 24\n",
      "val_acc 0.91552734 337\n",
      "tensor(1.2492, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 338 24\n",
      "val_acc 0.9213867 338\n",
      "tensor(1.2340, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 339 24\n",
      "val_acc 0.921875 339\n",
      "tensor(1.2207, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 340 24\n",
      "val_acc 0.9194336 340\n",
      "tensor(1.2363, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 341 24\n",
      "val_acc 0.921875 341\n",
      "tensor(1.2408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.925207756232687 342 24\n",
      "val_acc 0.91845703 342\n",
      "tensor(1.2154, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 343 24\n",
      "val_acc 0.92285156 343\n",
      "tensor(1.2480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 344 24\n",
      "val_acc 0.92041016 344\n",
      "tensor(1.2418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 345 24\n",
      "val_acc 0.92333984 345\n",
      "tensor(1.2259, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 346 24\n",
      "val_acc 0.92285156 346\n",
      "tensor(1.2300, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 347 24\n",
      "val_acc 0.921875 347\n",
      "tensor(1.2453, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 348 24\n",
      "val_acc 0.92333984 348\n",
      "tensor(1.2354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 349 24\n",
      "val_acc 0.9243164 349\n",
      "tensor(1.2271, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 350 24\n",
      "val_acc 0.92822266 350\n",
      "tensor(1.2578, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9113573407202216 351 24\n",
      "val_acc 0.9267578 351\n",
      "tensor(1.2314, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 352 24\n",
      "val_acc 0.92333984 352\n",
      "tensor(1.2241, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 353 24\n",
      "val_acc 0.9243164 353\n",
      "tensor(1.2274, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 354 24\n",
      "val_acc 0.91845703 354\n",
      "tensor(1.2323, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 355 24\n",
      "val_acc 0.92871094 355\n",
      "tensor(1.2326, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 356 24\n",
      "val_acc 0.9248047 356\n",
      "tensor(1.2295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 357 24\n",
      "val_acc 0.9301758 357\n",
      "tensor(1.2315, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 358 24\n",
      "val_acc 0.9350586 358\n",
      "tensor(1.2347, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 359 24\n",
      "val_acc 0.9277344 359\n",
      "tensor(1.2386, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 360 24\n",
      "val_acc 0.9301758 360\n",
      "tensor(1.2255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 361 24\n",
      "val_acc 0.92626953 361\n",
      "tensor(1.2258, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 362 24\n",
      "val_acc 0.9345703 362\n",
      "tensor(1.2385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 363 24\n",
      "val_acc 0.93603516 363\n",
      "tensor(1.2239, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 364 24\n",
      "val_acc 0.9375 364\n",
      "tensor(1.2208, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 365 24\n",
      "val_acc 0.9404297 365\n",
      "tensor(1.2263, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 366 24\n",
      "val_acc 0.9375 366\n",
      "tensor(1.2276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 367 24\n",
      "val_acc 0.9326172 367\n",
      "tensor(1.2219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 368 24\n",
      "val_acc 0.94189453 368\n",
      "tensor(1.2228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 369 24\n",
      "val_acc 0.94189453 369\n",
      "tensor(1.2457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 370 24\n",
      "val_acc 0.9394531 370\n",
      "tensor(1.2229, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 371 24\n",
      "val_acc 0.94189453 371\n",
      "tensor(1.2386, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.925207756232687 372 24\n",
      "val_acc 0.9433594 372\n",
      "tensor(1.2352, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 373 24\n",
      "val_acc 0.9277344 373\n",
      "tensor(1.2512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 374 24\n",
      "val_acc 0.9301758 374\n",
      "tensor(1.2414, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 375 24\n",
      "val_acc 0.93896484 375\n",
      "tensor(1.2104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 376 24\n",
      "val_acc 0.9272461 376\n",
      "tensor(1.2314, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 377 24\n",
      "val_acc 0.93652344 377\n",
      "tensor(1.2246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 378 24\n",
      "val_acc 0.94433594 378\n",
      "tensor(1.2313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 379 24\n",
      "val_acc 0.94433594 379\n",
      "tensor(1.2248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 380 24\n",
      "val_acc 0.94628906 380\n",
      "tensor(1.1956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 381 24\n",
      "val_acc 0.9453125 381\n",
      "tensor(1.2240, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 382 24\n",
      "val_acc 0.9448242 382\n",
      "tensor(1.1920, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 383 24\n",
      "val_acc 0.94384766 383\n",
      "tensor(1.2246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 384 24\n",
      "val_acc 0.94628906 384\n",
      "tensor(1.2281, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 385 24\n",
      "val_acc 0.9482422 385\n",
      "tensor(1.2410, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.925207756232687 386 24\n",
      "val_acc 0.94873047 386\n",
      "tensor(1.2255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 387 24\n",
      "val_acc 0.9477539 387\n",
      "tensor(1.2001, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 388 24\n",
      "val_acc 0.9506836 388\n",
      "tensor(1.2451, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 389 24\n",
      "val_acc 0.9506836 389\n",
      "tensor(1.2426, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 390 24\n",
      "val_acc 0.9506836 390\n",
      "tensor(1.2343, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 391 24\n",
      "val_acc 0.9501953 391\n",
      "tensor(1.2098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 392 24\n",
      "val_acc 0.95166016 392\n",
      "tensor(1.2203, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 393 24\n",
      "val_acc 0.953125 393\n",
      "tensor(1.2219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 394 24\n",
      "val_acc 0.9506836 394\n",
      "tensor(1.1992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 395 24\n",
      "val_acc 0.95214844 395\n",
      "tensor(1.2226, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 396 24\n",
      "val_acc 0.9506836 396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2212, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 397 24\n",
      "val_acc 0.9506836 397\n",
      "tensor(1.2279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 398 24\n",
      "val_acc 0.9501953 398\n",
      "tensor(1.2179, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 399 24\n",
      "val_acc 0.9482422 399\n",
      "tensor(1.2189, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 400 24\n",
      "val_acc 0.9506836 400\n",
      "tensor(1.2168, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 401 24\n",
      "val_acc 0.95166016 401\n",
      "tensor(1.2139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 402 24\n",
      "val_acc 0.94873047 402\n",
      "tensor(1.2365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 403 24\n",
      "val_acc 0.95166016 403\n",
      "tensor(1.2172, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 404 24\n",
      "val_acc 0.94970703 404\n",
      "tensor(1.2033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 405 24\n",
      "val_acc 0.9506836 405\n",
      "tensor(1.2264, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 406 24\n",
      "val_acc 0.95166016 406\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 407 24\n",
      "val_acc 0.9482422 407\n",
      "tensor(1.2167, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 408 24\n",
      "val_acc 0.9526367 408\n",
      "tensor(1.2021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 409 24\n",
      "val_acc 0.9536133 409\n",
      "tensor(1.2129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 410 24\n",
      "val_acc 0.9526367 410\n",
      "tensor(1.2069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 411 24\n",
      "val_acc 0.94970703 411\n",
      "tensor(1.2295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 412 24\n",
      "val_acc 0.95166016 412\n",
      "tensor(1.2128, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 413 24\n",
      "val_acc 0.9501953 413\n",
      "tensor(1.2316, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 414 24\n",
      "val_acc 0.9448242 414\n",
      "tensor(1.2256, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 415 24\n",
      "val_acc 0.94628906 415\n",
      "tensor(1.2280, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 416 24\n",
      "val_acc 0.94677734 416\n",
      "tensor(1.2066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 417 24\n",
      "val_acc 0.9536133 417\n",
      "tensor(1.2129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 418 24\n",
      "val_acc 0.9526367 418\n",
      "tensor(1.2352, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 419 24\n",
      "val_acc 0.94970703 419\n",
      "tensor(1.2046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 420 24\n",
      "val_acc 0.9506836 420\n",
      "tensor(1.1959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 421 24\n",
      "val_acc 0.95166016 421\n",
      "tensor(1.2313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 422 24\n",
      "val_acc 0.9526367 422\n",
      "tensor(1.2046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 423 24\n",
      "val_acc 0.9506836 423\n",
      "tensor(1.2002, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 424 24\n",
      "val_acc 0.9453125 424\n",
      "tensor(1.2164, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 425 24\n",
      "val_acc 0.9506836 425\n",
      "tensor(1.2202, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 426 24\n",
      "val_acc 0.9506836 426\n",
      "tensor(1.2345, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 427 24\n",
      "val_acc 0.9506836 427\n",
      "tensor(1.2068, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 428 24\n",
      "val_acc 0.95214844 428\n",
      "tensor(1.2394, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.925207756232687 429 24\n",
      "val_acc 0.9506836 429\n",
      "tensor(1.2045, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 430 24\n",
      "val_acc 0.953125 430\n",
      "tensor(1.2373, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 431 24\n",
      "val_acc 0.9399414 431\n",
      "tensor(1.2381, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 432 24\n",
      "val_acc 0.94921875 432\n",
      "tensor(1.1983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 433 24\n",
      "val_acc 0.94384766 433\n",
      "tensor(1.2035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 434 24\n",
      "val_acc 0.94384766 434\n",
      "tensor(1.2072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 435 24\n",
      "val_acc 0.9506836 435\n",
      "tensor(1.2187, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 436 24\n",
      "val_acc 0.95166016 436\n",
      "tensor(1.2075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 437 24\n",
      "val_acc 0.9511719 437\n",
      "tensor(1.2052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 438 24\n",
      "val_acc 0.9501953 438\n",
      "tensor(1.2156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 439 24\n",
      "val_acc 0.9501953 439\n",
      "tensor(1.2213, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 440 24\n",
      "val_acc 0.94970703 440\n",
      "tensor(1.2271, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 441 24\n",
      "val_acc 0.9506836 441\n",
      "tensor(1.2218, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 442 24\n",
      "val_acc 0.95166016 442\n",
      "tensor(1.1941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 443 24\n",
      "val_acc 0.953125 443\n",
      "tensor(1.2128, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 444 24\n",
      "val_acc 0.953125 444\n",
      "tensor(1.2197, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 445 24\n",
      "val_acc 0.95166016 445\n",
      "tensor(1.2088, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 446 24\n",
      "val_acc 0.9511719 446\n",
      "tensor(1.2044, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 447 24\n",
      "val_acc 0.95410156 447\n",
      "tensor(1.2055, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 448 24\n",
      "val_acc 0.953125 448\n",
      "tensor(1.2356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 449 24\n",
      "val_acc 0.9501953 449\n",
      "tensor(1.2100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 450 24\n",
      "val_acc 0.95214844 450\n",
      "tensor(1.2306, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 451 24\n",
      "val_acc 0.9482422 451\n",
      "tensor(1.2860, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8864265927977839 452 24\n",
      "val_acc 0.9121094 452\n",
      "tensor(1.2552, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9113573407202216 453 24\n",
      "val_acc 0.85595703 453\n",
      "tensor(1.2408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 454 24\n",
      "val_acc 0.9145508 454\n",
      "tensor(1.2328, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 455 24\n",
      "val_acc 0.9453125 455\n",
      "tensor(1.2125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 456 24\n",
      "val_acc 0.94970703 456\n",
      "tensor(1.2341, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 457 24\n",
      "val_acc 0.9477539 457\n",
      "tensor(1.2298, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 458 24\n",
      "val_acc 0.9526367 458\n",
      "tensor(1.2122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 459 24\n",
      "val_acc 0.9536133 459\n",
      "tensor(1.2018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 460 24\n",
      "val_acc 0.953125 460\n",
      "tensor(1.2017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 461 24\n",
      "val_acc 0.9536133 461\n",
      "tensor(1.1894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 462 24\n",
      "val_acc 0.953125 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2131, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 463 24\n",
      "val_acc 0.953125 463\n",
      "tensor(1.2170, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 464 24\n",
      "val_acc 0.95214844 464\n",
      "tensor(1.2195, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 465 24\n",
      "val_acc 0.95214844 465\n",
      "tensor(1.2100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 466 24\n",
      "val_acc 0.953125 466\n",
      "tensor(1.2075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 467 24\n",
      "val_acc 0.95214844 467\n",
      "tensor(1.2022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 468 24\n",
      "val_acc 0.953125 468\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 469 24\n",
      "val_acc 0.9526367 469\n",
      "tensor(1.1977, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 470 24\n",
      "val_acc 0.9536133 470\n",
      "tensor(1.2081, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 471 24\n",
      "val_acc 0.95410156 471\n",
      "tensor(1.2151, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 472 24\n",
      "val_acc 0.953125 472\n",
      "tensor(1.2096, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 473 24\n",
      "val_acc 0.9477539 473\n",
      "tensor(1.2040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 474 24\n",
      "val_acc 0.95458984 474\n",
      "tensor(1.2082, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 475 24\n",
      "val_acc 0.94873047 475\n",
      "tensor(1.1986, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 476 24\n",
      "val_acc 0.94873047 476\n",
      "tensor(1.2038, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 477 24\n",
      "val_acc 0.95214844 477\n",
      "tensor(1.2053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 478 24\n",
      "val_acc 0.9526367 478\n",
      "tensor(1.2192, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 479 24\n",
      "val_acc 0.9555664 479\n",
      "tensor(1.1972, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 480 24\n",
      "val_acc 0.953125 480\n",
      "tensor(1.1950, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 481 24\n",
      "val_acc 0.9550781 481\n",
      "tensor(1.2224, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 482 24\n",
      "val_acc 0.953125 482\n",
      "tensor(1.2086, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 483 24\n",
      "val_acc 0.9550781 483\n",
      "tensor(1.2359, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 484 24\n",
      "val_acc 0.95166016 484\n",
      "tensor(1.2206, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 485 24\n",
      "val_acc 0.95214844 485\n",
      "tensor(1.2120, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 486 24\n",
      "val_acc 0.9482422 486\n",
      "tensor(1.2029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 487 24\n",
      "val_acc 0.9536133 487\n",
      "tensor(1.1962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 488 24\n",
      "val_acc 0.9536133 488\n",
      "tensor(1.2153, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 489 24\n",
      "val_acc 0.95410156 489\n",
      "tensor(1.2216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 490 24\n",
      "val_acc 0.953125 490\n",
      "tensor(1.2223, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 491 24\n",
      "val_acc 0.95214844 491\n",
      "tensor(1.1958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 492 24\n",
      "val_acc 0.95166016 492\n",
      "tensor(1.2082, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 493 24\n",
      "val_acc 0.95214844 493\n",
      "tensor(1.2015, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 494 24\n",
      "val_acc 0.95214844 494\n",
      "tensor(1.2149, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 495 24\n",
      "val_acc 0.9477539 495\n",
      "tensor(1.1971, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 496 24\n",
      "val_acc 0.94873047 496\n",
      "tensor(1.2100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 497 24\n",
      "val_acc 0.9433594 497\n",
      "tensor(1.2062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 498 24\n",
      "val_acc 0.95410156 498\n",
      "tensor(1.2009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 499 24\n",
      "val_acc 0.9536133 499\n",
      "tensor(1.2063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 500 24\n",
      "val_acc 0.9550781 500\n",
      "tensor(1.2017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 501 24\n",
      "val_acc 0.9550781 501\n",
      "tensor(1.2214, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 502 24\n",
      "val_acc 0.95410156 502\n",
      "tensor(1.2126, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 503 24\n",
      "val_acc 0.9526367 503\n",
      "tensor(1.2204, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 504 24\n",
      "val_acc 0.95214844 504\n",
      "tensor(1.4377, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7202216066481995 505 24\n",
      "val_acc 0.7036133 505\n",
      "tensor(1.2596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9113573407202216 506 24\n",
      "val_acc 0.8676758 506\n",
      "tensor(1.2060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 507 24\n",
      "val_acc 0.94140625 507\n",
      "tensor(1.2181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 508 24\n",
      "val_acc 0.95166016 508\n",
      "tensor(1.2121, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 509 24\n",
      "val_acc 0.95410156 509\n",
      "tensor(1.2030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 510 24\n",
      "val_acc 0.953125 510\n",
      "tensor(1.1890, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 511 24\n",
      "val_acc 0.9536133 511\n",
      "tensor(1.2029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 512 24\n",
      "val_acc 0.95410156 512\n",
      "tensor(1.2109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 513 24\n",
      "val_acc 0.95214844 513\n",
      "tensor(1.2140, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 514 24\n",
      "val_acc 0.9550781 514\n",
      "tensor(1.2078, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 515 24\n",
      "val_acc 0.95214844 515\n",
      "tensor(1.2308, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 516 24\n",
      "val_acc 0.9550781 516\n",
      "tensor(1.1962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 517 24\n",
      "val_acc 0.9555664 517\n",
      "tensor(1.2040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 518 24\n",
      "val_acc 0.95458984 518\n",
      "tensor(1.2090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 519 24\n",
      "val_acc 0.9560547 519\n",
      "tensor(1.2194, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 520 24\n",
      "val_acc 0.9555664 520\n",
      "tensor(1.2307, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9335180055401662 521 24\n",
      "val_acc 0.95654297 521\n",
      "tensor(1.1919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 522 24\n",
      "val_acc 0.9560547 522\n",
      "tensor(1.2243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 523 24\n",
      "val_acc 0.9560547 523\n",
      "tensor(1.2024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 524 24\n",
      "val_acc 0.9555664 524\n",
      "tensor(1.1989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 525 24\n",
      "val_acc 0.9550781 525\n",
      "tensor(1.2103, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 526 24\n",
      "val_acc 0.9550781 526\n",
      "tensor(1.2333, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 527 24\n",
      "val_acc 0.9555664 527\n",
      "tensor(1.1965, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 528 24\n",
      "val_acc 0.95410156 528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 529 24\n",
      "val_acc 0.9550781 529\n",
      "tensor(1.2042, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 530 24\n",
      "val_acc 0.9550781 530\n",
      "tensor(1.2109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 531 24\n",
      "val_acc 0.9555664 531\n",
      "tensor(1.2230, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 532 24\n",
      "val_acc 0.9560547 532\n",
      "tensor(1.2262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 533 24\n",
      "val_acc 0.95654297 533\n",
      "tensor(1.2010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 534 24\n",
      "val_acc 0.9560547 534\n",
      "tensor(1.2079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 535 24\n",
      "val_acc 0.95458984 535\n",
      "tensor(1.2145, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 536 24\n",
      "val_acc 0.9555664 536\n",
      "tensor(1.1901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 537 24\n",
      "val_acc 0.95410156 537\n",
      "tensor(1.2091, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 538 24\n",
      "val_acc 0.95458984 538\n",
      "tensor(1.1973, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 539 24\n",
      "val_acc 0.95458984 539\n",
      "tensor(1.2013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 540 24\n",
      "val_acc 0.95410156 540\n",
      "tensor(1.1951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 541 24\n",
      "val_acc 0.95458984 541\n",
      "tensor(1.2314, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9362880886426593 542 24\n",
      "val_acc 0.95703125 542\n",
      "tensor(1.2023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 543 24\n",
      "val_acc 0.95703125 543\n",
      "tensor(1.1985, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 544 24\n",
      "val_acc 0.95751953 544\n",
      "tensor(1.1892, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 545 24\n",
      "val_acc 0.9584961 545\n",
      "tensor(1.2031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 546 24\n",
      "val_acc 0.9589844 546\n",
      "tensor(1.2058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 547 24\n",
      "val_acc 0.9609375 547\n",
      "tensor(1.2000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 548 24\n",
      "val_acc 0.95751953 548\n",
      "tensor(1.2233, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 549 24\n",
      "val_acc 0.9604492 549\n",
      "tensor(1.2185, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 550 24\n",
      "val_acc 0.95947266 550\n",
      "tensor(1.2057, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 551 24\n",
      "val_acc 0.96191406 551\n",
      "tensor(1.2027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 552 24\n",
      "val_acc 0.9628906 552\n",
      "tensor(1.2129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 553 24\n",
      "val_acc 0.9550781 553\n",
      "tensor(1.1959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 554 24\n",
      "val_acc 0.9628906 554\n",
      "tensor(1.2028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 555 24\n",
      "val_acc 0.9614258 555\n",
      "tensor(1.2216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 556 24\n",
      "val_acc 0.89990234 556\n",
      "tensor(1.2342, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 557 24\n",
      "val_acc 0.8979492 557\n",
      "tensor(1.2422, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9224376731301939 558 24\n",
      "val_acc 0.9248047 558\n",
      "tensor(1.2051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 559 24\n",
      "val_acc 0.95166016 559\n",
      "tensor(1.2043, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 560 24\n",
      "val_acc 0.9580078 560\n",
      "tensor(1.2063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 561 24\n",
      "val_acc 0.95654297 561\n",
      "tensor(1.2139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 562 24\n",
      "val_acc 0.9584961 562\n",
      "tensor(1.2003, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 563 24\n",
      "val_acc 0.96484375 563\n",
      "tensor(1.2014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 564 24\n",
      "val_acc 0.96484375 564\n",
      "tensor(1.1933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 565 24\n",
      "val_acc 0.96484375 565\n",
      "tensor(1.2103, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 566 24\n",
      "val_acc 0.96435547 566\n",
      "tensor(1.1829, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 567 24\n",
      "val_acc 0.96435547 567\n",
      "tensor(1.2013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 568 24\n",
      "val_acc 0.9628906 568\n",
      "tensor(1.1989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 569 24\n",
      "val_acc 0.9628906 569\n",
      "tensor(1.1827, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 570 24\n",
      "val_acc 0.9638672 570\n",
      "tensor(1.1942, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 571 24\n",
      "val_acc 0.9628906 571\n",
      "tensor(1.1989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 572 24\n",
      "val_acc 0.96240234 572\n",
      "tensor(1.2002, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 573 24\n",
      "val_acc 0.9614258 573\n",
      "tensor(1.1902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 574 24\n",
      "val_acc 0.9638672 574\n",
      "tensor(1.1961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 575 24\n",
      "val_acc 0.9614258 575\n",
      "tensor(1.1925, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 576 24\n",
      "val_acc 0.9633789 576\n",
      "tensor(1.2022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 577 24\n",
      "val_acc 0.9638672 577\n",
      "tensor(1.2060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 578 24\n",
      "val_acc 0.9614258 578\n",
      "tensor(1.2021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 579 24\n",
      "val_acc 0.96191406 579\n",
      "tensor(1.1897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 580 24\n",
      "val_acc 0.96435547 580\n",
      "tensor(1.1984, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 581 24\n",
      "val_acc 0.96435547 581\n",
      "tensor(1.2011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 582 24\n",
      "val_acc 0.9614258 582\n",
      "tensor(1.2078, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 583 24\n",
      "val_acc 0.96240234 583\n",
      "tensor(1.1979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 584 24\n",
      "val_acc 0.96435547 584\n",
      "tensor(1.2095, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 585 24\n",
      "val_acc 0.96435547 585\n",
      "tensor(1.1992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 586 24\n",
      "val_acc 0.96435547 586\n",
      "tensor(1.1891, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 587 24\n",
      "val_acc 0.96435547 587\n",
      "tensor(1.1986, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 588 24\n",
      "val_acc 0.96484375 588\n",
      "tensor(1.2036, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 589 24\n",
      "val_acc 0.96435547 589\n",
      "tensor(1.1829, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 590 24\n",
      "val_acc 0.96484375 590\n",
      "tensor(1.2055, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 591 24\n",
      "val_acc 0.96240234 591\n",
      "tensor(1.1910, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 592 24\n",
      "val_acc 0.96484375 592\n",
      "tensor(1.1997, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 593 24\n",
      "val_acc 0.96484375 593\n",
      "tensor(1.2178, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 594 24\n",
      "val_acc 0.96435547 594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2006, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 595 24\n",
      "val_acc 0.9633789 595\n",
      "tensor(1.2010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 596 24\n",
      "val_acc 0.9633789 596\n",
      "tensor(1.2037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 597 24\n",
      "val_acc 0.9633789 597\n",
      "tensor(1.2039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 598 24\n",
      "val_acc 0.9633789 598\n",
      "tensor(1.2001, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 599 24\n",
      "val_acc 0.9638672 599\n",
      "tensor(1.1879, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 600 24\n",
      "val_acc 0.96435547 600\n",
      "tensor(1.2005, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 601 24\n",
      "val_acc 0.9628906 601\n",
      "tensor(1.2010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 602 24\n",
      "val_acc 0.96240234 602\n",
      "tensor(1.2239, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 603 24\n",
      "val_acc 0.9614258 603\n",
      "tensor(1.1989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 604 24\n",
      "val_acc 0.9633789 604\n",
      "tensor(1.2028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 605 24\n",
      "val_acc 0.96191406 605\n",
      "tensor(1.2309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 606 24\n",
      "val_acc 0.9555664 606\n",
      "tensor(1.3317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 607 24\n",
      "val_acc 0.86816406 607\n",
      "tensor(1.2457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9279778393351801 608 24\n",
      "val_acc 0.9248047 608\n",
      "tensor(1.2248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 609 24\n",
      "val_acc 0.95996094 609\n",
      "tensor(1.2110, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 610 24\n",
      "val_acc 0.96435547 610\n",
      "tensor(1.1974, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 611 24\n",
      "val_acc 0.9633789 611\n",
      "tensor(1.2115, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 612 24\n",
      "val_acc 0.96435547 612\n",
      "tensor(1.2061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 613 24\n",
      "val_acc 0.96191406 613\n",
      "tensor(1.2064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 614 24\n",
      "val_acc 0.96435547 614\n",
      "tensor(1.1974, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 615 24\n",
      "val_acc 0.96191406 615\n",
      "tensor(1.1930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 616 24\n",
      "val_acc 0.9633789 616\n",
      "tensor(1.1973, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 617 24\n",
      "val_acc 0.96435547 617\n",
      "tensor(1.2009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 618 24\n",
      "val_acc 0.96435547 618\n",
      "tensor(1.2083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 619 24\n",
      "val_acc 0.96484375 619\n",
      "tensor(1.1997, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 620 24\n",
      "val_acc 0.9638672 620\n",
      "tensor(1.2166, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 621 24\n",
      "val_acc 0.9638672 621\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 622 24\n",
      "val_acc 0.96191406 622\n",
      "tensor(1.1906, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 623 24\n",
      "val_acc 0.96435547 623\n",
      "tensor(1.1973, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 624 24\n",
      "val_acc 0.96484375 624\n",
      "tensor(1.1958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 625 24\n",
      "val_acc 0.96240234 625\n",
      "tensor(1.1987, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 626 24\n",
      "val_acc 0.9638672 626\n",
      "tensor(1.1961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 627 24\n",
      "val_acc 0.96435547 627\n",
      "tensor(1.1956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 628 24\n",
      "val_acc 0.9638672 628\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 629 24\n",
      "val_acc 0.9638672 629\n",
      "tensor(1.2152, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 630 24\n",
      "val_acc 0.9633789 630\n",
      "tensor(1.1825, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 631 24\n",
      "val_acc 0.96484375 631\n",
      "tensor(1.2072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 632 24\n",
      "val_acc 0.96191406 632\n",
      "tensor(1.2081, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 633 24\n",
      "val_acc 0.9633789 633\n",
      "tensor(1.2053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 634 24\n",
      "val_acc 0.96484375 634\n",
      "tensor(1.1850, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 635 24\n",
      "val_acc 0.9638672 635\n",
      "tensor(1.2087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 636 24\n",
      "val_acc 0.9628906 636\n",
      "tensor(1.1980, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 637 24\n",
      "val_acc 0.9638672 637\n",
      "tensor(1.1981, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 638 24\n",
      "val_acc 0.9628906 638\n",
      "tensor(1.2082, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 639 24\n",
      "val_acc 0.96435547 639\n",
      "tensor(1.1871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 640 24\n",
      "val_acc 0.9638672 640\n",
      "tensor(1.1989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 641 24\n",
      "val_acc 0.9628906 641\n",
      "tensor(1.1889, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 642 24\n",
      "val_acc 0.96435547 642\n",
      "tensor(1.1828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 643 24\n",
      "val_acc 0.96240234 643\n",
      "tensor(1.2033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 644 24\n",
      "val_acc 0.96435547 644\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 645 24\n",
      "val_acc 0.9633789 645\n",
      "tensor(1.2020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 646 24\n",
      "val_acc 0.96435547 646\n",
      "tensor(1.1870, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 647 24\n",
      "val_acc 0.96435547 647\n",
      "tensor(1.1989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 648 24\n",
      "val_acc 0.96484375 648\n",
      "tensor(1.2020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 649 24\n",
      "val_acc 0.96435547 649\n",
      "tensor(1.1949, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 650 24\n",
      "val_acc 0.96484375 650\n",
      "tensor(1.1984, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 651 24\n",
      "val_acc 0.9638672 651\n",
      "tensor(1.2129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 652 24\n",
      "val_acc 0.96240234 652\n",
      "tensor(1.2090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 653 24\n",
      "val_acc 0.96435547 653\n",
      "tensor(1.1949, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 654 24\n",
      "val_acc 0.96435547 654\n",
      "tensor(1.2098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 655 24\n",
      "val_acc 0.9638672 655\n",
      "tensor(1.1892, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 656 24\n",
      "val_acc 0.96191406 656\n",
      "tensor(1.2027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 657 24\n",
      "val_acc 0.9628906 657\n",
      "tensor(1.1990, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 658 24\n",
      "val_acc 0.9628906 658\n",
      "tensor(1.1991, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 659 24\n",
      "val_acc 0.96191406 659\n",
      "tensor(1.1909, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 660 24\n",
      "val_acc 0.9633789 660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1910, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 661 24\n",
      "val_acc 0.9633789 661\n",
      "tensor(1.2066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 662 24\n",
      "val_acc 0.96484375 662\n",
      "tensor(1.1907, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 663 24\n",
      "val_acc 0.96435547 663\n",
      "tensor(1.2126, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 664 24\n",
      "val_acc 0.9628906 664\n",
      "tensor(1.1878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 665 24\n",
      "val_acc 0.96484375 665\n",
      "tensor(1.2033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 666 24\n",
      "val_acc 0.9658203 666\n",
      "tensor(1.2150, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 667 24\n",
      "val_acc 0.9633789 667\n",
      "tensor(1.1878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 668 24\n",
      "val_acc 0.9614258 668\n",
      "tensor(1.2171, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 669 24\n",
      "val_acc 0.96533203 669\n",
      "tensor(1.1970, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 670 24\n",
      "val_acc 0.9633789 670\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 671 24\n",
      "val_acc 0.9614258 671\n",
      "tensor(1.2239, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 672 24\n",
      "val_acc 0.9560547 672\n",
      "tensor(1.2942, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8781163434903048 673 24\n",
      "val_acc 0.90722656 673\n",
      "tensor(1.3100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8448753462603878 674 24\n",
      "val_acc 0.9013672 674\n",
      "tensor(1.2405, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9307479224376731 675 24\n",
      "val_acc 0.9526367 675\n",
      "tensor(1.2075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 676 24\n",
      "val_acc 0.96435547 676\n",
      "tensor(1.1825, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 677 24\n",
      "val_acc 0.96533203 677\n",
      "tensor(1.2013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 678 24\n",
      "val_acc 0.96533203 678\n",
      "tensor(1.1964, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 679 24\n",
      "val_acc 0.9638672 679\n",
      "tensor(1.2005, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 680 24\n",
      "val_acc 0.96484375 680\n",
      "tensor(1.1854, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 681 24\n",
      "val_acc 0.9633789 681\n",
      "tensor(1.1964, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 682 24\n",
      "val_acc 0.9628906 682\n",
      "tensor(1.1916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 683 24\n",
      "val_acc 0.96484375 683\n",
      "tensor(1.1903, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 684 24\n",
      "val_acc 0.9638672 684\n",
      "tensor(1.1986, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 685 24\n",
      "val_acc 0.96533203 685\n",
      "tensor(1.1987, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 686 24\n",
      "val_acc 0.9633789 686\n",
      "tensor(1.1970, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 687 24\n",
      "val_acc 0.9638672 687\n",
      "tensor(1.1970, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 688 24\n",
      "val_acc 0.96533203 688\n",
      "tensor(1.1949, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 689 24\n",
      "val_acc 0.96533203 689\n",
      "tensor(1.1978, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 690 24\n",
      "val_acc 0.96533203 690\n",
      "tensor(1.2118, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 691 24\n",
      "val_acc 0.96435547 691\n",
      "tensor(1.1827, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 692 24\n",
      "val_acc 0.9633789 692\n",
      "tensor(1.1770, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 693 24\n",
      "val_acc 0.96484375 693\n",
      "tensor(1.1992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 694 24\n",
      "val_acc 0.9633789 694\n",
      "tensor(1.1935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 695 24\n",
      "val_acc 0.96484375 695\n",
      "tensor(1.1993, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 696 24\n",
      "val_acc 0.96435547 696\n",
      "tensor(1.2089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 697 24\n",
      "val_acc 0.96240234 697\n",
      "tensor(1.2070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 698 24\n",
      "val_acc 0.96533203 698\n",
      "tensor(1.2055, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 699 24\n",
      "val_acc 0.96533203 699\n",
      "tensor(1.1954, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 700 24\n",
      "val_acc 0.96533203 700\n",
      "tensor(1.2136, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 701 24\n",
      "val_acc 0.96435547 701\n",
      "tensor(1.1931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 702 24\n",
      "val_acc 0.9609375 702\n",
      "tensor(1.1811, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 703 24\n",
      "val_acc 0.9633789 703\n",
      "tensor(1.2106, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 704 24\n",
      "val_acc 0.96533203 704\n",
      "tensor(1.1960, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 705 24\n",
      "val_acc 0.9658203 705\n",
      "tensor(1.2214, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9418282548476454 706 24\n",
      "val_acc 0.9638672 706\n",
      "tensor(1.2001, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 707 24\n",
      "val_acc 0.96533203 707\n",
      "tensor(1.1938, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 708 24\n",
      "val_acc 0.9658203 708\n",
      "tensor(1.1961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 709 24\n",
      "val_acc 0.96240234 709\n",
      "tensor(1.1979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 710 24\n",
      "val_acc 0.9663086 710\n",
      "tensor(1.1941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 711 24\n",
      "val_acc 0.9663086 711\n",
      "tensor(1.1927, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 712 24\n",
      "val_acc 0.9658203 712\n",
      "tensor(1.2049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 713 24\n",
      "val_acc 0.96484375 713\n",
      "tensor(1.2051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 714 24\n",
      "val_acc 0.96777344 714\n",
      "tensor(1.1992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 715 24\n",
      "val_acc 0.96484375 715\n",
      "tensor(1.2088, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 716 24\n",
      "val_acc 0.96728516 716\n",
      "tensor(1.2017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 717 24\n",
      "val_acc 0.96484375 717\n",
      "tensor(1.2069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 718 24\n",
      "val_acc 0.9614258 718\n",
      "tensor(1.1888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 719 24\n",
      "val_acc 0.95996094 719\n",
      "tensor(1.1904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 720 24\n",
      "val_acc 0.9663086 720\n",
      "tensor(1.1959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 721 24\n",
      "val_acc 0.96533203 721\n",
      "tensor(1.1938, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 722 24\n",
      "val_acc 0.9682617 722\n",
      "tensor(1.2017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 723 24\n",
      "val_acc 0.9638672 723\n",
      "tensor(1.2041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 724 24\n",
      "val_acc 0.95703125 724\n",
      "tensor(1.2488, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9196675900277008 725 24\n",
      "val_acc 0.92871094 725\n",
      "tensor(1.2173, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 726 24\n",
      "val_acc 0.9472656 726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 727 24\n",
      "val_acc 0.96728516 727\n",
      "tensor(1.1962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 728 24\n",
      "val_acc 0.9682617 728\n",
      "tensor(1.2067, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 729 24\n",
      "val_acc 0.96972656 729\n",
      "tensor(1.1830, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 730 24\n",
      "val_acc 0.96875 730\n",
      "tensor(1.1899, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 731 24\n",
      "val_acc 0.96777344 731\n",
      "tensor(1.1935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 732 24\n",
      "val_acc 0.9682617 732\n",
      "tensor(1.1849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 733 24\n",
      "val_acc 0.9667969 733\n",
      "tensor(1.1884, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 734 24\n",
      "val_acc 0.97021484 734\n",
      "tensor(1.1886, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 735 24\n",
      "val_acc 0.9682617 735\n",
      "tensor(1.2138, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 736 24\n",
      "val_acc 0.96728516 736\n",
      "tensor(1.1882, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 737 24\n",
      "val_acc 0.96728516 737\n",
      "tensor(1.1961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 738 24\n",
      "val_acc 0.9663086 738\n",
      "tensor(1.1983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 739 24\n",
      "val_acc 0.96875 739\n",
      "tensor(1.2032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 740 24\n",
      "val_acc 0.97021484 740\n",
      "tensor(1.1966, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 741 24\n",
      "val_acc 0.96875 741\n",
      "tensor(1.1912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 742 24\n",
      "val_acc 0.9692383 742\n",
      "tensor(1.1886, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 743 24\n",
      "val_acc 0.9711914 743\n",
      "tensor(1.2141, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 744 24\n",
      "val_acc 0.96875 744\n",
      "tensor(1.1964, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 745 24\n",
      "val_acc 0.97216797 745\n",
      "tensor(1.2049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 746 24\n",
      "val_acc 0.96728516 746\n",
      "tensor(1.1888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 747 24\n",
      "val_acc 0.9663086 747\n",
      "tensor(1.2017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 748 24\n",
      "val_acc 0.97021484 748\n",
      "tensor(1.1921, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 749 24\n",
      "val_acc 0.9682617 749\n",
      "tensor(1.1913, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 750 24\n",
      "val_acc 0.96728516 750\n",
      "tensor(1.2212, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 751 24\n",
      "val_acc 0.9711914 751\n",
      "tensor(1.2559, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9168975069252078 752 24\n",
      "val_acc 0.9145508 752\n",
      "tensor(1.2681, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8975069252077562 753 24\n",
      "val_acc 0.9067383 753\n",
      "tensor(1.3042, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8642659279778393 754 24\n",
      "val_acc 0.8457031 754\n",
      "tensor(1.2247, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9445983379501385 755 24\n",
      "val_acc 0.9604492 755\n",
      "tensor(1.1983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 756 24\n",
      "val_acc 0.9746094 756\n",
      "tensor(1.1838, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 757 24\n",
      "val_acc 0.9760742 757\n",
      "tensor(1.1960, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 758 24\n",
      "val_acc 0.97753906 758\n",
      "tensor(1.1922, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 759 24\n",
      "val_acc 0.9770508 759\n",
      "tensor(1.1832, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 760 24\n",
      "val_acc 0.9765625 760\n",
      "tensor(1.1962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 761 24\n",
      "val_acc 0.97509766 761\n",
      "tensor(1.1919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 762 24\n",
      "val_acc 0.9770508 762\n",
      "tensor(1.2053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 763 24\n",
      "val_acc 0.9765625 763\n",
      "tensor(1.1897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 764 24\n",
      "val_acc 0.9785156 764\n",
      "tensor(1.1843, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 765 24\n",
      "val_acc 0.97802734 765\n",
      "tensor(1.1896, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 766 24\n",
      "val_acc 0.97753906 766\n",
      "tensor(1.2020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 767 24\n",
      "val_acc 0.97509766 767\n",
      "tensor(1.1926, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 768 24\n",
      "val_acc 0.97753906 768\n",
      "tensor(1.2085, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 769 24\n",
      "val_acc 0.97802734 769\n",
      "tensor(1.2074, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 770 24\n",
      "val_acc 0.9790039 770\n",
      "tensor(1.1883, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 771 24\n",
      "val_acc 0.9790039 771\n",
      "tensor(1.1956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 772 24\n",
      "val_acc 0.9790039 772\n",
      "tensor(1.1906, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 773 24\n",
      "val_acc 0.9736328 773\n",
      "tensor(1.1767, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 774 24\n",
      "val_acc 0.9794922 774\n",
      "tensor(1.1938, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 775 24\n",
      "val_acc 0.97802734 775\n",
      "tensor(1.1956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 776 24\n",
      "val_acc 0.9794922 776\n",
      "tensor(1.1928, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 777 24\n",
      "val_acc 0.9794922 777\n",
      "tensor(1.1828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 778 24\n",
      "val_acc 0.97998047 778\n",
      "tensor(1.1936, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 779 24\n",
      "val_acc 0.97998047 779\n",
      "tensor(1.1853, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 780 24\n",
      "val_acc 0.98046875 780\n",
      "tensor(1.1931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 781 24\n",
      "val_acc 0.9790039 781\n",
      "tensor(1.2145, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 782 24\n",
      "val_acc 0.9790039 782\n",
      "tensor(1.2011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 783 24\n",
      "val_acc 0.97998047 783\n",
      "tensor(1.1920, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 784 24\n",
      "val_acc 0.97998047 784\n",
      "tensor(1.1789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 785 24\n",
      "val_acc 0.9794922 785\n",
      "tensor(1.1826, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 786 24\n",
      "val_acc 0.97265625 786\n",
      "tensor(1.1882, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 787 24\n",
      "val_acc 0.97802734 787\n",
      "tensor(1.1880, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 788 24\n",
      "val_acc 0.98046875 788\n",
      "tensor(1.1799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 789 24\n",
      "val_acc 0.9794922 789\n",
      "tensor(1.1895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 790 24\n",
      "val_acc 0.97998047 790\n",
      "tensor(1.1980, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 791 24\n",
      "val_acc 0.9790039 791\n",
      "tensor(1.1907, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 792 24\n",
      "val_acc 0.97509766 792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1864, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 793 24\n",
      "val_acc 0.98046875 793\n",
      "tensor(1.1824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 794 24\n",
      "val_acc 0.9790039 794\n",
      "tensor(1.1876, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 795 24\n",
      "val_acc 0.97998047 795\n",
      "tensor(1.1995, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 796 24\n",
      "val_acc 0.9794922 796\n",
      "tensor(1.2064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 797 24\n",
      "val_acc 0.98046875 797\n",
      "tensor(1.1956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 798 24\n",
      "val_acc 0.9794922 798\n",
      "tensor(1.1775, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 799 24\n",
      "val_acc 0.97998047 799\n",
      "tensor(1.1988, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 800 24\n",
      "val_acc 0.98095703 800\n",
      "tensor(1.1874, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 801 24\n",
      "val_acc 0.98291016 801\n",
      "tensor(1.1983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 802 24\n",
      "val_acc 0.98046875 802\n",
      "tensor(1.1833, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 803 24\n",
      "val_acc 0.97998047 803\n",
      "tensor(1.1934, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 804 24\n",
      "val_acc 0.9790039 804\n",
      "tensor(1.1865, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 805 24\n",
      "val_acc 0.9682617 805\n",
      "tensor(1.1964, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 806 24\n",
      "val_acc 0.98095703 806\n",
      "tensor(1.1926, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 807 24\n",
      "val_acc 0.9819336 807\n",
      "tensor(1.1856, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 808 24\n",
      "val_acc 0.98291016 808\n",
      "tensor(1.1826, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 809 24\n",
      "val_acc 0.9819336 809\n",
      "tensor(1.1876, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 810 24\n",
      "val_acc 0.98291016 810\n",
      "tensor(1.1854, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 811 24\n",
      "val_acc 0.9824219 811\n",
      "tensor(1.1850, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 812 24\n",
      "val_acc 0.98046875 812\n",
      "tensor(1.1979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 813 24\n",
      "val_acc 0.97998047 813\n",
      "tensor(1.1908, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 814 24\n",
      "val_acc 0.97998047 814\n",
      "tensor(1.1828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 815 24\n",
      "val_acc 0.98339844 815\n",
      "tensor(1.1843, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 816 24\n",
      "val_acc 0.9819336 816\n",
      "tensor(1.1964, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 817 24\n",
      "val_acc 0.98291016 817\n",
      "tensor(1.1904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 818 24\n",
      "val_acc 0.98339844 818\n",
      "tensor(1.1799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 819 24\n",
      "val_acc 0.98339844 819\n",
      "tensor(1.1982, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 820 24\n",
      "val_acc 0.9824219 820\n",
      "tensor(1.1935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 821 24\n",
      "val_acc 0.9814453 821\n",
      "tensor(1.2068, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 822 24\n",
      "val_acc 0.98046875 822\n",
      "tensor(1.1929, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 823 24\n",
      "val_acc 0.98339844 823\n",
      "tensor(1.1937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 824 24\n",
      "val_acc 0.98339844 824\n",
      "tensor(1.1928, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 825 24\n",
      "val_acc 0.98339844 825\n",
      "tensor(1.1851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 826 24\n",
      "val_acc 0.9814453 826\n",
      "tensor(1.1796, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 827 24\n",
      "val_acc 0.9819336 827\n",
      "tensor(1.1911, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 828 24\n",
      "val_acc 0.984375 828\n",
      "tensor(1.1885, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 829 24\n",
      "val_acc 0.9824219 829\n",
      "tensor(1.1836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 830 24\n",
      "val_acc 0.9838867 830\n",
      "tensor(1.1864, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 831 24\n",
      "val_acc 0.9814453 831\n",
      "tensor(1.1991, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 832 24\n",
      "val_acc 0.9838867 832\n",
      "tensor(1.1713, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9944598337950139 833 24\n",
      "val_acc 0.984375 833\n",
      "tensor(1.1968, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 834 24\n",
      "val_acc 0.984375 834\n",
      "tensor(1.1776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 835 24\n",
      "val_acc 0.98046875 835\n",
      "tensor(1.1848, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 836 24\n",
      "val_acc 0.9814453 836\n",
      "tensor(1.1771, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 837 24\n",
      "val_acc 0.984375 837\n",
      "tensor(1.1771, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 838 24\n",
      "val_acc 0.98339844 838\n",
      "tensor(1.1742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 839 24\n",
      "val_acc 0.984375 839\n",
      "tensor(1.1794, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 840 24\n",
      "val_acc 0.98291016 840\n",
      "tensor(1.1797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 841 24\n",
      "val_acc 0.98095703 841\n",
      "tensor(1.1984, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 842 24\n",
      "val_acc 0.97509766 842\n",
      "tensor(1.1818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 843 24\n",
      "val_acc 0.9838867 843\n",
      "tensor(1.1796, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 844 24\n",
      "val_acc 0.984375 844\n",
      "tensor(1.1879, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 845 24\n",
      "val_acc 0.9765625 845\n",
      "tensor(1.1929, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 846 24\n",
      "val_acc 0.9819336 846\n",
      "tensor(1.1719, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9944598337950139 847 24\n",
      "val_acc 0.9848633 847\n",
      "tensor(1.1837, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 848 24\n",
      "val_acc 0.984375 848\n",
      "tensor(1.1932, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 849 24\n",
      "val_acc 0.98339844 849\n",
      "tensor(1.1902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 850 24\n",
      "val_acc 0.98291016 850\n",
      "tensor(1.1863, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 851 24\n",
      "val_acc 0.984375 851\n",
      "tensor(1.2039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 852 24\n",
      "val_acc 0.98095703 852\n",
      "tensor(1.1915, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 853 24\n",
      "val_acc 0.9838867 853\n",
      "tensor(1.1768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 854 24\n",
      "val_acc 0.98339844 854\n",
      "tensor(1.2079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 855 24\n",
      "val_acc 0.9814453 855\n",
      "tensor(1.1771, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 856 24\n",
      "val_acc 0.984375 856\n",
      "tensor(1.1796, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 857 24\n",
      "val_acc 0.9848633 857\n",
      "tensor(1.1863, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 858 24\n",
      "val_acc 0.984375 858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 859 24\n",
      "val_acc 0.97802734 859\n",
      "tensor(1.1803, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 860 24\n",
      "val_acc 0.9838867 860\n",
      "tensor(1.1878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 861 24\n",
      "val_acc 0.9838867 861\n",
      "tensor(1.1910, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 862 24\n",
      "val_acc 0.98339844 862\n",
      "tensor(1.2040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 863 24\n",
      "val_acc 0.9819336 863\n",
      "tensor(1.1741, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 864 24\n",
      "val_acc 0.98291016 864\n",
      "tensor(1.1930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 865 24\n",
      "val_acc 0.9814453 865\n",
      "tensor(1.1770, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 866 24\n",
      "val_acc 0.9794922 866\n",
      "tensor(1.2012, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 867 24\n",
      "val_acc 0.97802734 867\n",
      "tensor(1.1783, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 868 24\n",
      "val_acc 0.984375 868\n",
      "tensor(1.2238, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9501385041551247 869 24\n",
      "val_acc 0.8979492 869\n",
      "tensor(1.4419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7174515235457064 870 24\n",
      "val_acc 0.6455078 870\n",
      "tensor(1.3914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.7645429362880887 871 24\n",
      "val_acc 0.77246094 871\n",
      "tensor(1.3195, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.850415512465374 872 24\n",
      "val_acc 0.88623047 872\n",
      "tensor(1.3090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8559556786703602 873 24\n",
      "val_acc 0.87939453 873\n",
      "tensor(1.2642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9002770083102493 874 24\n",
      "val_acc 0.9140625 874\n",
      "tensor(1.2270, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9390581717451524 875 24\n",
      "val_acc 0.9477539 875\n",
      "tensor(1.1821, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 876 24\n",
      "val_acc 0.9741211 876\n",
      "tensor(1.1830, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 877 24\n",
      "val_acc 0.9814453 877\n",
      "tensor(1.1830, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 878 24\n",
      "val_acc 0.98291016 878\n",
      "tensor(1.1809, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 879 24\n",
      "val_acc 0.9838867 879\n",
      "tensor(1.1822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 880 24\n",
      "val_acc 0.9838867 880\n",
      "tensor(1.1778, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 881 24\n",
      "val_acc 0.98339844 881\n",
      "tensor(1.1829, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 882 24\n",
      "val_acc 0.98339844 882\n",
      "tensor(1.1800, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 883 24\n",
      "val_acc 0.9848633 883\n",
      "tensor(1.1882, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 884 24\n",
      "val_acc 0.9848633 884\n",
      "tensor(1.1931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 885 24\n",
      "val_acc 0.9848633 885\n",
      "tensor(1.1748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 886 24\n",
      "val_acc 0.9848633 886\n",
      "tensor(1.1768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 887 24\n",
      "val_acc 0.9848633 887\n",
      "tensor(1.1979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 888 24\n",
      "val_acc 0.9848633 888\n",
      "tensor(1.1875, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 889 24\n",
      "val_acc 0.9824219 889\n",
      "tensor(1.1941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 890 24\n",
      "val_acc 0.98339844 890\n",
      "tensor(1.1822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 891 24\n",
      "val_acc 0.9824219 891\n",
      "tensor(1.1893, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 892 24\n",
      "val_acc 0.9838867 892\n",
      "tensor(1.1713, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9944598337950139 893 24\n",
      "val_acc 0.98339844 893\n",
      "tensor(1.1858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 894 24\n",
      "val_acc 0.9824219 894\n",
      "tensor(1.1945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 895 24\n",
      "val_acc 0.9824219 895\n",
      "tensor(1.1876, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 896 24\n",
      "val_acc 0.9824219 896\n",
      "tensor(1.1865, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 897 24\n",
      "val_acc 0.9838867 897\n",
      "tensor(1.1793, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 898 24\n",
      "val_acc 0.98339844 898\n",
      "tensor(1.1853, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 899 24\n",
      "val_acc 0.98339844 899\n",
      "tensor(1.1877, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 900 24\n",
      "val_acc 0.984375 900\n",
      "tensor(1.1849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 901 24\n",
      "val_acc 0.98339844 901\n",
      "tensor(1.1894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 902 24\n",
      "val_acc 0.9838867 902\n",
      "tensor(1.1740, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 903 24\n",
      "val_acc 0.9838867 903\n",
      "tensor(1.1902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 904 24\n",
      "val_acc 0.98339844 904\n",
      "tensor(1.1773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 905 24\n",
      "val_acc 0.9848633 905\n",
      "tensor(1.1918, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 906 24\n",
      "val_acc 0.9838867 906\n",
      "tensor(1.1744, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 907 24\n",
      "val_acc 0.98095703 907\n",
      "tensor(1.1871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 908 24\n",
      "val_acc 0.9838867 908\n",
      "tensor(1.1992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 909 24\n",
      "val_acc 0.9770508 909\n",
      "tensor(1.1769, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 910 24\n",
      "val_acc 0.9824219 910\n",
      "tensor(1.1901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 911 24\n",
      "val_acc 0.9760742 911\n",
      "tensor(1.1825, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 912 24\n",
      "val_acc 0.9790039 912\n",
      "tensor(1.1805, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 913 24\n",
      "val_acc 0.984375 913\n",
      "tensor(1.1767, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 914 24\n",
      "val_acc 0.984375 914\n",
      "tensor(1.1857, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 915 24\n",
      "val_acc 0.9838867 915\n",
      "tensor(1.1978, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 916 24\n",
      "val_acc 0.9848633 916\n",
      "tensor(1.1847, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 917 24\n",
      "val_acc 0.98339844 917\n",
      "tensor(1.1872, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 918 24\n",
      "val_acc 0.9819336 918\n",
      "tensor(1.1750, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 919 24\n",
      "val_acc 0.9848633 919\n",
      "tensor(1.2065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9584487534626038 920 24\n",
      "val_acc 0.9824219 920\n",
      "tensor(1.1961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 921 24\n",
      "val_acc 0.98339844 921\n",
      "tensor(1.1955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 922 24\n",
      "val_acc 0.9824219 922\n",
      "tensor(1.1876, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 923 24\n",
      "val_acc 0.984375 923\n",
      "tensor(1.1816, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 924 24\n",
      "val_acc 0.9848633 924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1873, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 925 24\n",
      "val_acc 0.98339844 925\n",
      "tensor(1.1792, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 926 24\n",
      "val_acc 0.9819336 926\n",
      "tensor(1.1822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 927 24\n",
      "val_acc 0.98291016 927\n",
      "tensor(1.1908, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 928 24\n",
      "val_acc 0.9824219 928\n",
      "tensor(1.2190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9473684210526315 929 24\n",
      "val_acc 0.96728516 929\n",
      "tensor(1.1752, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 930 24\n",
      "val_acc 0.9790039 930\n",
      "tensor(1.1801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 931 24\n",
      "val_acc 0.9838867 931\n",
      "tensor(1.1971, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 932 24\n",
      "val_acc 0.984375 932\n",
      "tensor(1.1824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 933 24\n",
      "val_acc 0.9848633 933\n",
      "tensor(1.1849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 934 24\n",
      "val_acc 0.9814453 934\n",
      "tensor(1.1777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 935 24\n",
      "val_acc 0.98339844 935\n",
      "tensor(1.1787, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 936 24\n",
      "val_acc 0.9765625 936\n",
      "tensor(1.1840, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 937 24\n",
      "val_acc 0.9824219 937\n",
      "tensor(1.1831, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 938 24\n",
      "val_acc 0.984375 938\n",
      "tensor(1.1871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 939 24\n",
      "val_acc 0.984375 939\n",
      "tensor(1.1899, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 940 24\n",
      "val_acc 0.984375 940\n",
      "tensor(1.1834, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 941 24\n",
      "val_acc 0.984375 941\n",
      "tensor(1.1738, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 942 24\n",
      "val_acc 0.9848633 942\n",
      "tensor(1.1770, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 943 24\n",
      "val_acc 0.9848633 943\n",
      "tensor(1.1892, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 944 24\n",
      "val_acc 0.9838867 944\n",
      "tensor(1.1766, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 945 24\n",
      "val_acc 0.9848633 945\n",
      "tensor(1.1766, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 946 24\n",
      "val_acc 0.9838867 946\n",
      "tensor(1.1821, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 947 24\n",
      "val_acc 0.98291016 947\n",
      "tensor(1.1903, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 948 24\n",
      "val_acc 0.984375 948\n",
      "tensor(1.1790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 949 24\n",
      "val_acc 0.984375 949\n",
      "tensor(1.2109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9529085872576177 950 24\n",
      "val_acc 0.97998047 950\n",
      "tensor(1.1903, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 951 24\n",
      "val_acc 0.9824219 951\n",
      "tensor(1.1876, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 952 24\n",
      "val_acc 0.9848633 952\n",
      "tensor(1.1833, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 953 24\n",
      "val_acc 0.9848633 953\n",
      "tensor(1.1847, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 954 24\n",
      "val_acc 0.9824219 954\n",
      "tensor(1.1796, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 955 24\n",
      "val_acc 0.9838867 955\n",
      "tensor(1.2091, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 956 24\n",
      "val_acc 0.9814453 956\n",
      "tensor(1.1858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 957 24\n",
      "val_acc 0.98339844 957\n",
      "tensor(1.1831, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 958 24\n",
      "val_acc 0.9838867 958\n",
      "tensor(1.1871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 959 24\n",
      "val_acc 0.9838867 959\n",
      "tensor(1.1844, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 960 24\n",
      "val_acc 0.9814453 960\n",
      "tensor(1.1878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 961 24\n",
      "val_acc 0.97558594 961\n",
      "tensor(1.1810, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 962 24\n",
      "val_acc 0.9848633 962\n",
      "tensor(1.1986, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 963 24\n",
      "val_acc 0.9824219 963\n",
      "tensor(1.1742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 964 24\n",
      "val_acc 0.9838867 964\n",
      "tensor(1.1803, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 965 24\n",
      "val_acc 0.9848633 965\n",
      "tensor(1.2032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.961218836565097 966 24\n",
      "val_acc 0.98339844 966\n",
      "tensor(1.1948, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 967 24\n",
      "val_acc 0.984375 967\n",
      "tensor(1.1888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 968 24\n",
      "val_acc 0.9838867 968\n",
      "tensor(1.1818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9833795013850416 969 24\n",
      "val_acc 0.9736328 969\n",
      "tensor(1.2000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 970 24\n",
      "val_acc 0.97753906 970\n",
      "tensor(1.1777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 971 24\n",
      "val_acc 0.9814453 971\n",
      "tensor(1.1928, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9722991689750693 972 24\n",
      "val_acc 0.9838867 972\n",
      "tensor(1.1957, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 973 24\n",
      "val_acc 0.9838867 973\n",
      "tensor(1.1765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9889196675900277 974 24\n",
      "val_acc 0.9838867 974\n",
      "tensor(1.1661, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 1.0 975 24\n",
      "val_acc 0.9838867 975\n",
      "tensor(1.1952, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 976 24\n",
      "val_acc 0.98339844 976\n",
      "tensor(1.1949, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 977 24\n",
      "val_acc 0.9838867 977\n",
      "tensor(1.1889, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 978 24\n",
      "val_acc 0.9824219 978\n",
      "tensor(1.1846, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 979 24\n",
      "val_acc 0.984375 979\n",
      "tensor(1.1848, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 980 24\n",
      "val_acc 0.9848633 980\n",
      "tensor(1.1991, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.96398891966759 981 24\n",
      "val_acc 0.98339844 981\n",
      "tensor(1.1861, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 982 24\n",
      "val_acc 0.9838867 982\n",
      "tensor(1.1883, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 983 24\n",
      "val_acc 0.9824219 983\n",
      "tensor(1.1956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 984 24\n",
      "val_acc 0.98291016 984\n",
      "tensor(1.1738, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9916897506925207 985 24\n",
      "val_acc 0.9814453 985\n",
      "tensor(1.1887, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 986 24\n",
      "val_acc 0.984375 986\n",
      "tensor(1.1961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9695290858725761 987 24\n",
      "val_acc 0.9785156 987\n",
      "tensor(1.2094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9556786703601108 988 24\n",
      "val_acc 0.98339844 988\n",
      "tensor(1.1848, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9806094182825484 989 24\n",
      "val_acc 0.9770508 989\n",
      "tensor(1.1901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 990 24\n",
      "val_acc 0.97998047 990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8365650969529086 991 24\n",
      "val_acc 0.81640625 991\n",
      "tensor(1.3105, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8559556786703602 992 24\n",
      "val_acc 0.86035156 992\n",
      "tensor(1.2693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.8975069252077562 993 24\n",
      "val_acc 0.9423828 993\n",
      "tensor(1.2018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 994 24\n",
      "val_acc 0.9794922 994\n",
      "tensor(1.1890, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9778393351800554 995 24\n",
      "val_acc 0.9848633 995\n",
      "tensor(1.1980, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9667590027700831 996 24\n",
      "val_acc 0.9848633 996\n",
      "tensor(1.1714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9944598337950139 997 24\n",
      "val_acc 0.9848633 997\n",
      "tensor(1.1799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9861495844875346 998 24\n",
      "val_acc 0.984375 998\n",
      "tensor(1.1899, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>) 0.9750692520775623 999 24\n",
      "val_acc 0.984375 999\n"
     ]
    }
   ],
   "source": [
    "classifier=ElementClassifier().to(float).cuda()\n",
    "optimizer=torch.optim.Adam(classifier.parameters(),lr=0.0001)\n",
    "lossfn=torch.nn.CrossEntropyLoss()\n",
    "#inps=specsrestored\n",
    "inps=distributions.T\n",
    "inps=torch.tensor(inps.T).unsqueeze(1).to(float).cuda()#[:10000]\n",
    "targlist=[(col.split(',')[0][2:-1],col.split(',')[1][2:-1]) for col in Alldata.columns[:-1]]#[:10000]\n",
    "encoder={}\n",
    "decoder={}\n",
    "losses=[]\n",
    "accs=[]\n",
    "vallosses=[]\n",
    "valaccs=[]\n",
    "for i,k in enumerate(set(targlist)):\n",
    "    encoder[k]=i\n",
    "    decoder[i]=k\n",
    "targs=torch.nn.functional.one_hot(torch.tensor([encoder[targ] for targ in targlist])).to(float).cuda()\n",
    "dataset = torch.utils.data.TensorDataset(inps, targs)\n",
    "train,test=torch.utils.data.random_split(dataset,[51561-2048,2048])\n",
    "loader=torch.utils.data.DataLoader(train, batch_size=8192*2//8, shuffle=True)\n",
    "for epoch in range(1000):\n",
    "    for i,batch in enumerate(loader):\n",
    "        inp,targ=batch\n",
    "        #A=i%25\n",
    "        #A=0\n",
    "        #inp,targ=inps[A*2000:A*2000+2000],targs[A*2000:A*2000+2000]\n",
    "        loss,acc=trainstepClass(classifier,inp*100,targ,optimizer)\n",
    "    print(loss,acc.cpu().numpy(),epoch,i)\n",
    "        #if i%100==0:\n",
    "    losses.append(loss.detach().cpu().numpy())\n",
    "    accs.append(acc.detach().cpu().numpy())\n",
    "    with torch.no_grad():\n",
    "        Ans=classifier(test[:][0]*100)\n",
    "        acc=(Ans.argmax(1)==test[:][1].argmax(1)).sum()/len(test)\n",
    "        valloss=torch.nn.CrossEntropyLoss()(Ans, test[:][1])\n",
    "        valaccs.append(acc.detach().cpu().numpy())\n",
    "        vallosses.append(valloss.detach().cpu().numpy())\n",
    "        print('val_acc' ,acc.cpu().numpy(),epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f1514e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=Ans.argmax(1).cpu() \n",
    "y_true=test[:][1].argmax(1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d4d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('losses.npy',np.array(losses))\n",
    "np.save('accs.npy',np.array(accs))\n",
    "np.save('vallosses.npy',np.array(vallosses))\n",
    "np.save('valaccs.npy',np.array(valaccs))\n",
    "np.save('pred.npy',np.array(y_pred))\n",
    "np.save('true.npy',np.array(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fddf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1aa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Ans.argmax(1).cpu(), test[:][1].argmax(1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1ccfaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 283,   0,   1,   0,   0,   0],\n",
       "       [  0,   0, 324,   0,   0,   0,   0],\n",
       "       [  0,   2,   0, 333,   0,   0,   0],\n",
       "       [  0,   9,   0,   0, 318,   0,   0],\n",
       "       [  0,  18,   0,   0,   0, 295,   0],\n",
       "       [  0,   2,   0,   0,   0,   0, 316]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2475991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f90aea52500>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_pred=y_pred, y_true=y_true, \n",
    "                                        display_labels=[str(decoder[i])[-4:-2] for i in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b156c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsall=[]\n",
    "with torch.no_grad():\n",
    "    for i in range(inps.shape[0]//2048+1):\n",
    "        predsall=predsall+list(classifier(inps[2048*i:2048*i+2048]*100).argmax(-1).cpu().numpy())\n",
    "    np.save('predsall.npy',np.array(predsall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37f8399b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, ..., 5, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralFixer(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(NeuralFixer, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(in_channels, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv1d(8, 2, kernel_size=3, padding=1)\n",
    "        # Layer 2\n",
    "        self.conv3 = torch.nn.Conv1d(2, 241, kernel_size=241, padding=0,bias=True)\n",
    "        self.relu =torch.nn.functional.relu\n",
    "        self.tanh=torch.nn.functional.tanh\n",
    "    def forward(self, z):\n",
    "        B,C,W=z.shape\n",
    "        #x = self.relu(self.adapt_nn(z)).cuda()\n",
    "        #x = x.view(x.size(0), self.in_channels, self.length // 2 // 2 // 2)\n",
    "        x = self.relu(self.conv1(z))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.tanh(self.conv3(x))\n",
    "        out =x.reshape(B,-1)\n",
    "        return out\n",
    "def trainstepfixer(model,inp,target, optimizer,lossfn=torch.nn.L1Loss()):\n",
    "    optimizer.zero_grad()\n",
    "    out=model(inp)\n",
    "    loss=lossfn(out, target)*100\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "060ec684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51561, 241)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alldata=Alldata.fillna(0)\n",
    "diff=torch.tensor(np.array(Alldata)[:,:-1]-specsrestored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsall=np.load('predsall.npy')\n",
    "alldata=np.array(Alldata)[:,:-1]\n",
    "nfixers=[NeuralFixer().to(float) for i in range(7)]\n",
    "for i in range(7):\n",
    "    inpchunk=torch.tensor(specsrestored[:,predsall==i].T*10).unsqueeze(1).to(float)#.cuda()\n",
    "    targchunk=torch.tensor(diff[:,predsall==i].T*10).to(float)#.cuda()\n",
    "    optimizer=torch.optim.Adam(nfixers[i].parameters())\n",
    "    for ctr in range(500):\n",
    "        loss=trainstepfixer(nfixers[i],inpchunk,targchunk,optimizer)\n",
    "        if ctr%10==0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    corrected=specsrestored.T.copy()*10\n",
    "    for i in range(7):\n",
    "        chunk=torch.tensor(corrected[predsall==i,:]).unsqueeze(1)\n",
    "        corrected[predsall==i,:]=corrected[predsall==i,:]+nfixers[i](chunk).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ea22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(nfixers):\n",
    "    torch.save('correctormodel_{}.pt'.format(encoder[i]),model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee520e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((specsrestored-alldata)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
